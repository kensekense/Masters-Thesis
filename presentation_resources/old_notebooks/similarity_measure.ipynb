{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Edit-distance operations are defined as \n",
    "* (a,a) denotes a match of symbols at the given position\n",
    "* (a,-) denotes deletion of symbol 'a' at some position\n",
    "* (-,b) denotes insertion of symbol 'b' at some position\n",
    "* (a,b) denotes replacement of 'a' with 'b' at some position, and a != b\n",
    "We assign a separate cost for each of these operations according to our needs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for simplicity and completeness sake, we define a simple levenshtein distance function first\n",
    "\n",
    "def basic_distance (trace1, trace2):\n",
    "\n",
    "    M = len(trace1)\n",
    "    N = len(trace2)\n",
    "    edit_table = np.zeros((M,N)) #establish table\n",
    "\n",
    "    #fill table\n",
    "    for i in range(M):\n",
    "        for j in range(N):\n",
    "\n",
    "            if i == 0:\n",
    "                edit_table[i][j] = j\n",
    "\n",
    "            elif j ==0:\n",
    "                edit_table[i][j] = i\n",
    "\n",
    "            elif trace1[i-1] == trace2[j-1]:\n",
    "                edit_table[i][j] = edit_table[i-1][j-1]\n",
    "\n",
    "            else:\n",
    "                edit_table[i][j] = 1 + min(edit_table[i-1][j], edit_table[i][j-1], edit_table[i-1][j-1]) #scoring done here\n",
    "\n",
    "    return edit_table[i][j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample test\n",
    "dat1 = pd.read_csv('./data/graham.norton.s22.e08_data.csv')\n",
    "dat2 = pd.read_csv('./data/graham.norton.s22.e12_data.csv')\n",
    "dat3 = pd.read_csv('./data/blackpink_data.csv')\n",
    "test1 = list(dat1.L)\n",
    "test2 = list(dat2.L)\n",
    "test3 = list(dat3.L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "670.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_distance(test1,test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [\"a\",\"a\",\"a\",\"a\",\"a\"]\n",
    "c = [\"a\",\"a\",\"a\",\"a\",\"a\"]\n",
    "b = [\"b\",\"b\",\"b\",\"b\",\"b\"]\n",
    "d = [\"a\",\"a\",\"a\",\"a\",\"a\",\"a\",\"a\",\"a\"]\n",
    "basic_distance(a,d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [\"a\",\"a\",\"a\",\"a\",\"b\",\"a\",\"c\",\"c\"]\n",
    "b = [\"b\",\"b\",\"b\",\"b\",\"a\",\"b\",\"c\",\"c\",\"c\",\"c\"]\n",
    "basic_distance(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "991.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_distance(test1, test3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "670"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#baseline\n",
    "import nltk\n",
    "nltk.edit_distance(test1,test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = [\"a\",\"b\"]\n",
    "t2 = [\"a\",\"b\",\"c\",\"d\"]\n",
    "nltk.edit_distance(t1,t2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we have to alter the function to accomodate for different scoring metrics according to the paper\n",
    "* substitution of uncorrelated activities should be discouraged\n",
    "* substitution of contrasting activities should be penalized\n",
    "* insertion of activities out of context should be discouraged\n",
    "* substitution of correlated activities should be encouraged in proportion to the degree of similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP 1: Define the symbols in the list of traces\n",
    "def define_symbols (traces):\n",
    "    assert type(traces) == list\n",
    "    symbols = []\n",
    "    for item in traces:\n",
    "        symbols.append(set(item))\n",
    "    x = symbols[0]\n",
    "    for i in range(len(symbols)):\n",
    "        x = x.union(symbols[i])\n",
    "    \n",
    "    return list(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['e', 'b', 'd', 'g', 'q', 'f', 'c', 'a']\n",
      "['b', 'd', 'c', 'a']\n",
      "['give.opinion', 'give.statement', 'relax.atmosphere', 'closed.question', 'recall', 'respond.deny', 'exclamation', 'respond.agree', 'open.question', 'use.social.convention', 'misc', 'quoted.speech', 'deflection']\n"
     ]
    }
   ],
   "source": [
    "# A != B\n",
    "a = [\"a\",\"b\",\"c\",\"d\",\"e\"]\n",
    "b = [\"a\",\"g\",\"q\",\"q\",\"e\",\"f\"]\n",
    "c = [a, b]\n",
    "print(define_symbols(c))\n",
    "\n",
    "# A == B\n",
    "a = [\"a\", \"b\", \"c\", \"d\"]\n",
    "b = [\"a\", \"a\", \"c\", \"d\", \"b\", \"b\"]\n",
    "c = [a,b]\n",
    "print(define_symbols(c))\n",
    "\n",
    "# on the dataset\n",
    "c = [test1,test2]\n",
    "print(define_symbols(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP 2: Define the set of all 3-grams in the logs and their frequencies\n",
    "def three_grams (traces):\n",
    "    assert type(traces) == list\n",
    "    g3 = []\n",
    "    g3_freq = {}\n",
    "    for trace in traces:\n",
    "        for i in range(len(trace)-2):\n",
    "            g3.append(\", \".join(list(trace[i:i+3])))\n",
    "            try:\n",
    "                g3_freq[\", \".join(list(trace[i:i+3]))] += 1\n",
    "            except:\n",
    "                g3_freq[\", \".join(list(trace[i:i+3]))] = 1\n",
    "    return list(set(g3)), g3_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['g, f, e', 'j, i, h', 'b, c, d', 'e, f, g', 'k, j, i', 'h, g, f', 'f, e, d', 'a, b, c', 'i, h, g', 'd, c, b', 'f, g, h', 'c, b, a', 'e, d, c', 'c, d, e', 'g, h, i', 'h, i, j', 'i, j, k', 'd, e, f'], {'a, b, c': 1, 'b, c, d': 1, 'c, d, e': 1, 'd, e, f': 1, 'e, f, g': 1, 'f, g, h': 1, 'g, h, i': 1, 'h, i, j': 1, 'i, j, k': 1, 'k, j, i': 1, 'j, i, h': 1, 'i, h, g': 1, 'h, g, f': 1, 'g, f, e': 1, 'f, e, d': 1, 'e, d, c': 1, 'd, c, b': 1, 'c, b, a': 1})\n",
      "(['b, c, d', 'e, f, g', 'a, b, c', 'f, g, h', 'c, d, e', 'g, h, i', 'h, i, j', 'i, j, k', 'd, e, f'], {'a, b, c': 2, 'b, c, d': 2, 'c, d, e': 2, 'd, e, f': 2, 'e, f, g': 2, 'f, g, h': 2, 'g, h, i': 2, 'h, i, j': 2, 'i, j, k': 2})\n"
     ]
    }
   ],
   "source": [
    "#A = abcdefghijk, B = kjihgfedcba\n",
    "a = [\"a\",\"b\",\"c\",\"d\",\"e\",\"f\",\"g\",\"h\",\"i\",\"j\",\"k\"]\n",
    "b = [\"k\",\"j\",\"i\",\"h\",\"g\",\"f\",\"e\",\"d\",\"c\",\"b\",\"a\"]\n",
    "c = [a,b]\n",
    "print(three_grams(c))\n",
    "\n",
    "#A = abcdefghijk, B = abcdefghijk\n",
    "a = [\"a\",\"b\",\"c\",\"d\",\"e\",\"f\",\"g\",\"h\",\"i\",\"j\",\"k\"]\n",
    "b = [\"a\",\"b\",\"c\",\"d\",\"e\",\"f\",\"g\",\"h\",\"i\",\"j\",\"k\"]\n",
    "c = [a,b]\n",
    "print(three_grams(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP 3: Define the context for symbol a\n",
    "def define_context(grams):\n",
    "    \n",
    "    assert type(grams) == list\n",
    "    \n",
    "    context = {}\n",
    "    for gram in grams:\n",
    "        x,a,y = gram.split(\", \")\n",
    "        try:\n",
    "            context[a].append(\"{0}, {1}\".format(x,y))\n",
    "        except:\n",
    "            context[a] = []\n",
    "            context[a].append(\"{0}, {1}\".format(x,y))\n",
    "            \n",
    "    #clear dups\n",
    "    for k in list(context.keys()):\n",
    "        context[k] = list(set(context[k]))\n",
    "    \n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': ['a, a'], 'b': ['b, b']}\n",
      "{'c': ['c, a', 'a, e', 'b, c'], 'e': ['c, f'], 'b': ['a, c', 'b, c', 'b, b'], 'a': ['a, b', 'a, c', 'a, a', 'f, a'], 'f': ['e, a']}\n"
     ]
    }
   ],
   "source": [
    "#test context, should have keys a and b, where each has aa and bb respectively\n",
    "a = [\"a\",\"a\",\"a\",\"a\",\"a\",\"a\",\"a\"]\n",
    "b = [\"b\",\"b\",\"b\",\"b\",\"b\"]\n",
    "c = [a,b]\n",
    "grams, g3_freq = three_grams(c)\n",
    "print(define_context(grams))\n",
    "\n",
    "#test context\n",
    "a = [\"a\",\"a\",\"a\",\"a\",\"a\",\"a\",\"a\",\"c\",\"e\",\"f\",\"a\",\"a\",\"b\",\"c\"]\n",
    "b = [\"b\",\"b\",\"b\",\"b\",\"b\",\"c\",\"c\",\"a\"]\n",
    "c = [a,b]\n",
    "grams, g3_freq = three_grams(c)\n",
    "print(define_context(grams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP 4: define pairs of context\n",
    "def context_pairs (context):\n",
    "    \n",
    "    assert type(context) == dict\n",
    "    \n",
    "    context_pairs = {}\n",
    "    for a in list(context.keys()):\n",
    "        for b in list(context.keys()):\n",
    "            if a != b:\n",
    "                context_pairs[\"{0}, {1}\".format(a, b)] = list(set(context[a]).intersection(set(context[b])))\n",
    "    \n",
    "    return context_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a, b': [], 'b, a': []}\n",
      "{'a, b': ['a, a', 'b, b'], 'b, a': ['a, a', 'b, b']}\n"
     ]
    }
   ],
   "source": [
    "#test context pairs, should be empty\n",
    "a = [\"a\",\"a\",\"a\",\"a\",\"a\",\"a\",\"a\"]\n",
    "b = [\"b\",\"b\",\"b\",\"b\",\"b\"]\n",
    "c = [a,b]\n",
    "grams, g3_freq = three_grams(c)\n",
    "context = define_context(grams)\n",
    "print(context_pairs(context))\n",
    "\n",
    "#test context pairs, should be aa and bb\n",
    "a = [\"a\",\"a\",\"a\",\"a\",\"b\",\"a\"]\n",
    "b = [\"b\",\"b\",\"b\",\"b\",\"a\",\"b\"]\n",
    "c = [a,b]\n",
    "grams, g3_freq = three_grams(c)\n",
    "context = define_context(grams)\n",
    "print(context_pairs(context))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP 5: define co-occurrence combinations\n",
    "def define_cooccurrence(symbols, context_pairs, gram_freq):\n",
    "    \n",
    "    assert type(context_pairs) == dict\n",
    "    assert type(gram_freq) == dict\n",
    "    assert type(symbols) == list\n",
    "    \n",
    "    co_occur = {}\n",
    "    for k in list(context_pairs.keys()):\n",
    "        for item in context_pairs[k]:\n",
    "            for a in symbols:\n",
    "                for b in symbols:\n",
    "                    x,y = item.split(\", \")[0], item.split(\", \")[1]\n",
    "                    if a == b:\n",
    "                        try:\n",
    "                            n = gram_freq[\"{0}, {1}, {2}\".format(x,a,y)]\n",
    "                            co_occur[\"{0}, {1}({2}, {3})\".format(x,y,a,b)] = (n*(n-1))/2\n",
    "                        except:\n",
    "                            co_occur[\"{0}, {1}({2}, {3})\".format(x,y,a,b)] = 0.0\n",
    "                        \n",
    "                    elif a != b:\n",
    "                        try:\n",
    "                            n_i = gram_freq[\"{0}, {1}, {2}\".format(x,a,y)]\n",
    "                            n_j = gram_freq[\"{0}, {1}, {2}\".format(x,b,y)]\n",
    "                            co_occur[\"{0}, {1}({2}, {3})\".format(x,y,a,b)] = n_i*n_j\n",
    "                        except:\n",
    "                            co_occur[\"{0}, {1}({2}, {3})\".format(x,y,a,b)] = 0.0\n",
    "    \n",
    "    return co_occur\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a, a, b', 'b, b, a', 'a, b, c', 'b, a, c', 'a, b, a', 'a, a, a', 'b, a, b', 'b, b, b']\n",
      "{'a, a, a': 2, 'a, a, b': 1, 'a, b, a': 1, 'b, a, c': 1, 'b, b, b': 2, 'b, b, a': 1, 'b, a, b': 1, 'a, b, c': 1}\n",
      "{'a': ['a, b', 'a, a', 'b, c', 'b, b'], 'b': ['b, a', 'a, c', 'a, a', 'b, b']}\n",
      "{'a, b': ['a, a', 'b, b'], 'b, a': ['a, a', 'b, b']}\n",
      "{'a, a(b, b)': 0.0, 'a, a(b, c)': 0.0, 'a, a(b, a)': 2, 'a, a(c, b)': 0.0, 'a, a(c, c)': 0.0, 'a, a(c, a)': 0.0, 'a, a(a, b)': 2, 'a, a(a, c)': 0.0, 'a, a(a, a)': 1.0, 'b, b(b, b)': 1.0, 'b, b(b, c)': 0.0, 'b, b(b, a)': 2, 'b, b(c, b)': 0.0, 'b, b(c, c)': 0.0, 'b, b(c, a)': 0.0, 'b, b(a, b)': 2, 'b, b(a, c)': 0.0, 'b, b(a, a)': 0.0}\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "a = [\"a\",\"a\",\"a\",\"a\",\"b\",\"a\",\"c\"]\n",
    "b = [\"b\",\"b\",\"b\",\"b\",\"a\",\"b\",\"c\"]\n",
    "c = [a,b]\n",
    "grams, g3_freq = three_grams(c)\n",
    "print(grams)\n",
    "print(g3_freq)\n",
    "context = define_context(grams)\n",
    "print(context)\n",
    "con_pairs = context_pairs(context)\n",
    "print(con_pairs)\n",
    "print(define_cooccurrence(define_symbols(c),con_pairs,g3_freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP 6: Define the count of co-occurrences for symbols a,b for all contexts\n",
    "def co_occur_combos(symbols, con_pairs, co_occurs):\n",
    "    assert type(symbols) == list\n",
    "    assert type(con_pairs) == dict\n",
    "    assert type(co_occurs) == dict\n",
    "    \n",
    "    co_occur_combos = {}\n",
    "    for a in symbols:\n",
    "        for b in symbols:\n",
    "            total = 0.0\n",
    "            for k in list(con_pairs.keys()):\n",
    "                for item in con_pairs[k]:\n",
    "                    total += co_occurs[\"{0}({1}, {2})\".format(item,a,b)]\n",
    "            co_occur_combos[\"{0}, {1}\".format(a,b)] = total\n",
    "    \n",
    "    return co_occur_combos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a, a, a': 4, 'a, a, b': 7, 'a, b, a': 6, 'b, a, a': 5, 'a, b, b': 1}\n",
      "{'a': ['a, b', 'b, a', 'a, a'], 'b': ['a, b', 'a, a']}\n",
      "{'a, b': ['a, b', 'a, a'], 'b, a': ['a, b', 'a, a']}\n",
      "{'a, b(b, b)': 0.0, 'a, b(b, a)': 7, 'a, b(a, b)': 7, 'a, b(a, a)': 21.0, 'a, a(b, b)': 15.0, 'a, a(b, a)': 24, 'a, a(a, b)': 24, 'a, a(a, a)': 6.0}\n",
      "{'b, b': 30.0, 'b, a': 62.0, 'a, b': 62.0, 'a, a': 54.0}\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "a = [\"a\",\"a\",\"a\",\"a\",\"b\",\"a\",\"a\",\"b\",\"b\"]\n",
    "b = [\"a\",\"a\",\"a\",\"a\",\"b\",\"a\",\"a\",\"b\",\"a\",\"a\",\"b\",\"a\",\"a\",\"b\",\"a\",\"a\",\"b\",\"a\"]\n",
    "c = [a,b]\n",
    "grams, g3_freq = three_grams(c)\n",
    "print(g3_freq)\n",
    "context = define_context(grams)\n",
    "print(context)\n",
    "con_pairs = context_pairs(context)\n",
    "print(con_pairs)\n",
    "co_occurs = define_cooccurrence(define_symbols(c),con_pairs,g3_freq)\n",
    "print(co_occurs)\n",
    "print(co_occur_combos(define_symbols(c),con_pairs,co_occurs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP 7: Define norm on the count of co-occur combos\n",
    "def define_norm (co_combos):\n",
    "    assert type(co_combos) == dict\n",
    "    norm = 0.0\n",
    "    for k in list(co_combos.keys()):\n",
    "        norm += co_combos[k]\n",
    "    \n",
    "    return norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208.0\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "a = [\"a\",\"a\",\"a\",\"a\",\"b\",\"a\",\"a\",\"b\",\"b\"]\n",
    "b = [\"a\",\"a\",\"a\",\"a\",\"b\",\"a\",\"a\",\"b\",\"a\",\"a\",\"b\",\"a\",\"a\",\"b\",\"a\",\"a\",\"b\",\"a\"]\n",
    "c = [a,b]\n",
    "grams, g3_freq = three_grams(c)\n",
    "context = define_context(grams)\n",
    "con_pairs = context_pairs(context)\n",
    "co_occurs = define_cooccurrence(define_symbols(c),con_pairs,g3_freq)\n",
    "print(define_norm(co_occur_combos(define_symbols(c),con_pairs,co_occurs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP 8: Define matrix M over A x A\n",
    "def define_matrix (symbols, co_combos, norm):\n",
    "    assert type(symbols) == list\n",
    "    assert type(co_combos) == dict\n",
    "    assert type(norm) == float\n",
    "    \n",
    "    mat_M = {}\n",
    "    for a in symbols:\n",
    "        for b in symbols:\n",
    "            mat_M[\"{0}, {1}\".format(a,b)] = co_combos[\"{0}, {1}\".format(a,b)]/norm\n",
    "    \n",
    "    return mat_M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'b, b': 0.14423076923076922, 'b, a': 0.2980769230769231, 'a, b': 0.2980769230769231, 'a, a': 0.25961538461538464}\n"
     ]
    }
   ],
   "source": [
    "a = [\"a\",\"a\",\"a\",\"a\",\"b\",\"a\",\"a\",\"b\",\"b\"]\n",
    "b = [\"a\",\"a\",\"a\",\"a\",\"b\",\"a\",\"a\",\"b\",\"a\",\"a\",\"b\",\"a\",\"a\",\"b\",\"a\",\"a\",\"b\",\"a\"]\n",
    "c = [a,b]\n",
    "grams, g3_freq = three_grams(c)\n",
    "context = define_context(grams)\n",
    "con_pairs = context_pairs(context)\n",
    "co_occurs = define_cooccurrence(define_symbols(c),con_pairs,g3_freq)\n",
    "norm = define_norm(co_occur_combos(define_symbols(c),con_pairs,co_occurs))\n",
    "co_combos = co_occur_combos(define_symbols(c), con_pairs, co_occurs)\n",
    "print(define_matrix(define_symbols(c), co_combos, norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_occur (symbols, mat_M):\n",
    "    assert type(symbols) == list\n",
    "    assert type(mat_M) == dict\n",
    "    \n",
    "    p = {}\n",
    "    for a in symbols:\n",
    "        total = 0\n",
    "        for b in symbols:\n",
    "            if a != b:\n",
    "                total += mat_M[\"{0}, {1}\".format(a,b)]\n",
    "        total += mat_M[\"{0}, {1}\".format(a,a)]\n",
    "        p[\"{0}\".format(a)] = total\n",
    "    \n",
    "    return p\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'b': 0.4423076923076923, 'a': 0.5576923076923077}\n"
     ]
    }
   ],
   "source": [
    "a = [\"a\",\"a\",\"a\",\"a\",\"b\",\"a\",\"a\",\"b\",\"b\"]\n",
    "b = [\"a\",\"a\",\"a\",\"a\",\"b\",\"a\",\"a\",\"b\",\"a\",\"a\",\"b\",\"a\",\"a\",\"b\",\"a\",\"a\",\"b\",\"a\"]\n",
    "c = [a,b]\n",
    "grams, g3_freq = three_grams(c)\n",
    "context = define_context(grams)\n",
    "con_pairs = context_pairs(context)\n",
    "co_occurs = define_cooccurrence(define_symbols(c),con_pairs,g3_freq)\n",
    "norm = define_norm(co_occur_combos(define_symbols(c),con_pairs,co_occurs))\n",
    "co_combos = co_occur_combos(define_symbols(c), con_pairs, co_occurs)\n",
    "matM = define_matrix(define_symbols(c), co_combos, norm)\n",
    "print(prob_occur(define_symbols(c), matM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_val (symbols, prob):\n",
    "    assert type(symbols) == list\n",
    "    assert type(prob) == dict\n",
    "    \n",
    "    e_val = {}\n",
    "    for a in symbols:\n",
    "        for b in symbols:\n",
    "            if a == b:\n",
    "                e_val[\"{0}, {1}\".format(a,b)] = prob[\"{0}\".format(a)]**2\n",
    "            else:\n",
    "                e_val[\"{0}, {1}\".format(a,b)] = 2*prob[\"{0}\".format(a)]*prob[\"{0}\".format(b)]\n",
    "    \n",
    "    return e_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'b, b': 0.1956360946745562, 'b, a': 0.4933431952662722, 'a, b': 0.4933431952662722, 'a, a': 0.3110207100591716}\n"
     ]
    }
   ],
   "source": [
    "a = [\"a\",\"a\",\"a\",\"a\",\"b\",\"a\",\"a\",\"b\",\"b\"]\n",
    "b = [\"a\",\"a\",\"a\",\"a\",\"b\",\"a\",\"a\",\"b\",\"a\",\"a\",\"b\",\"a\",\"a\",\"b\",\"a\",\"a\",\"b\",\"a\"]\n",
    "c = [a,b]\n",
    "grams, g3_freq = three_grams(c)\n",
    "context = define_context(grams)\n",
    "con_pairs = context_pairs(context)\n",
    "co_occurs = define_cooccurrence(define_symbols(c),con_pairs,g3_freq)\n",
    "norm = define_norm(co_occur_combos(define_symbols(c),con_pairs,co_occurs))\n",
    "co_combos = co_occur_combos(define_symbols(c), con_pairs, co_occurs)\n",
    "matM = define_matrix(define_symbols(c), co_combos, norm)\n",
    "probs = prob_occur(define_symbols(c), matM)\n",
    "print(exp_val(define_symbols(c), probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub_scores (traces):\n",
    "    assert type(traces) == list\n",
    "    \n",
    "    symbols = define_symbols(traces)\n",
    "    three_gs, three_gs_freq = three_grams(traces)\n",
    "    cons = define_context(three_gs)\n",
    "    con_pairs = context_pairs(cons)\n",
    "    co_occurs = define_cooccurrence(symbols, con_pairs, three_gs_freq)\n",
    "    co_combos = co_occur_combos(symbols, con_pairs, co_occurs)\n",
    "    norm = define_norm(co_combos)\n",
    "    matM = define_matrix(symbols, co_combos, norm)\n",
    "    probs = prob_occur(symbols, matM)\n",
    "    e_val = exp_val(symbols, probs)\n",
    "    \n",
    "    sub_costs = {}\n",
    "    for a in symbols:\n",
    "        for b in symbols:\n",
    "            if a!=b:\n",
    "                try:\n",
    "                    sub_costs[\"{0}, {1}\".format(a,b)] = np.log2(matM[\"{0}, {1}\".format(a,b)]/e_val[\"{0}, {1}\".format(a,b)])\n",
    "                except:\n",
    "                    sub_costs[\"{0}, {1}\".format(a,b)] = -1000\n",
    "    \n",
    "    return sub_costs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'give.opinion, give.statement': -1.551085076399558,\n",
       " 'give.opinion, relax.atmosphere': -1.3650380400618178,\n",
       " 'give.opinion, closed.question': -1.139522845910327,\n",
       " 'give.opinion, x': -0.6679891654646126,\n",
       " 'give.opinion, recall': -1.1929744100425526,\n",
       " 'give.opinion, respond.deny': -1.0729193484268291,\n",
       " 'give.opinion, exclamation': -0.7793724385005201,\n",
       " 'give.opinion, respond.agree': -1.0515448148414683,\n",
       " 'give.opinion, open.question': -1.5235479035656052,\n",
       " 'give.opinion, use.social.convention': -1.587120755005616,\n",
       " 'give.opinion, misc': -0.8011931628395911,\n",
       " 'give.opinion, quoted.speech': -0.548279866499742,\n",
       " 'give.opinion, deflection': -0.7705444199074922,\n",
       " 'give.statement, give.opinion': -1.551085076399558,\n",
       " 'give.statement, relax.atmosphere': 0.161794917912701,\n",
       " 'give.statement, closed.question': -0.49663267156671204,\n",
       " 'give.statement, x': -1.4430844811671424,\n",
       " 'give.statement, recall': -2.285814647337215,\n",
       " 'give.statement, respond.deny': -0.774043474918979,\n",
       " 'give.statement, exclamation': -1.5258346476842015,\n",
       " 'give.statement, respond.agree': -0.10231777490106037,\n",
       " 'give.statement, open.question': 0.20099939485635576,\n",
       " 'give.statement, use.social.convention': 0.06169904953965291,\n",
       " 'give.statement, misc': -2.419022881270522,\n",
       " 'give.statement, quoted.speech': -2.5346516835351456,\n",
       " 'give.statement, deflection': -1.2210821986910982,\n",
       " 'relax.atmosphere, give.opinion': -1.3650380400618178,\n",
       " 'relax.atmosphere, give.statement': 0.161794917912701,\n",
       " 'relax.atmosphere, closed.question': -0.25503679940030644,\n",
       " 'relax.atmosphere, x': -1.1929297472414884,\n",
       " 'relax.atmosphere, recall': -2.4576658194242196,\n",
       " 'relax.atmosphere, respond.deny': -0.6343370449038186,\n",
       " 'relax.atmosphere, exclamation': -1.0506168130627735,\n",
       " 'relax.atmosphere, respond.agree': -0.560418357212303,\n",
       " 'relax.atmosphere, open.question': 0.11514493379705423,\n",
       " 'relax.atmosphere, use.social.convention': -0.07555032343093558,\n",
       " 'relax.atmosphere, misc': -1.9790499282169394,\n",
       " 'relax.atmosphere, quoted.speech': -2.2923257903454175,\n",
       " 'relax.atmosphere, deflection': -1.3388027930736253,\n",
       " 'closed.question, give.opinion': -1.139522845910327,\n",
       " 'closed.question, give.statement': -0.49663267156671204,\n",
       " 'closed.question, relax.atmosphere': -0.25503679940030644,\n",
       " 'closed.question, x': -1.2652534366940584,\n",
       " 'closed.question, recall': -1.6681479072597993,\n",
       " 'closed.question, respond.deny': -0.3487318243260107,\n",
       " 'closed.question, exclamation': -1.7572986492139457,\n",
       " 'closed.question, respond.agree': -0.634471702166014,\n",
       " 'closed.question, open.question': 1.0681971719196177,\n",
       " 'closed.question, use.social.convention': -1.3623084823017624,\n",
       " 'closed.question, misc': -2.068973688731254,\n",
       " 'closed.question, quoted.speech': -1.7630448360769642,\n",
       " 'closed.question, deflection': -1.2221698704821877,\n",
       " 'x, give.opinion': -0.6679891654646126,\n",
       " 'x, give.statement': -1.4430844811671424,\n",
       " 'x, relax.atmosphere': -1.1929297472414884,\n",
       " 'x, closed.question': -1.2652534366940584,\n",
       " 'x, recall': -2.2445977361827776,\n",
       " 'x, respond.deny': -1.3634443601750523,\n",
       " 'x, exclamation': -1.419212334754892,\n",
       " 'x, respond.agree': -1.356355002800911,\n",
       " 'x, open.question': -1.5288902160423954,\n",
       " 'x, use.social.convention': -1.8297441027992374,\n",
       " 'x, misc': -1.548709208157624,\n",
       " 'x, quoted.speech': -1.3513125231489669,\n",
       " 'x, deflection': -1.453542325855465,\n",
       " 'recall, give.opinion': -1.1929744100425526,\n",
       " 'recall, give.statement': -2.285814647337215,\n",
       " 'recall, relax.atmosphere': -2.4576658194242196,\n",
       " 'recall, closed.question': -1.6681479072597993,\n",
       " 'recall, x': -2.2445977361827776,\n",
       " 'recall, respond.deny': -2.0482506487370613,\n",
       " 'recall, exclamation': -1.5789380346534259,\n",
       " 'recall, respond.agree': -2.1179976484521275,\n",
       " 'recall, open.question': -2.419114458195377,\n",
       " 'recall, use.social.convention': -2.318504923701657,\n",
       " 'recall, misc': -1.3657582748572212,\n",
       " 'recall, quoted.speech': -2.0460816817244223,\n",
       " 'recall, deflection': -2.4280474670924344,\n",
       " 'respond.deny, give.opinion': -1.0729193484268291,\n",
       " 'respond.deny, give.statement': -0.774043474918979,\n",
       " 'respond.deny, relax.atmosphere': -0.6343370449038186,\n",
       " 'respond.deny, closed.question': -0.3487318243260107,\n",
       " 'respond.deny, x': -1.3634443601750523,\n",
       " 'respond.deny, recall': -2.0482506487370613,\n",
       " 'respond.deny, exclamation': -1.1788264513011688,\n",
       " 'respond.deny, respond.agree': 0.4087439246476891,\n",
       " 'respond.deny, open.question': -0.2189693006010538,\n",
       " 'respond.deny, use.social.convention': -1.8379559606662978,\n",
       " 'respond.deny, misc': -1.9357816537394434,\n",
       " 'respond.deny, quoted.speech': -2.024701301385798,\n",
       " 'respond.deny, deflection': 0.30010617155309083,\n",
       " 'exclamation, give.opinion': -0.7793724385005201,\n",
       " 'exclamation, give.statement': -1.5258346476842015,\n",
       " 'exclamation, relax.atmosphere': -1.0506168130627735,\n",
       " 'exclamation, closed.question': -1.7572986492139457,\n",
       " 'exclamation, x': -1.419212334754892,\n",
       " 'exclamation, recall': -1.5789380346534259,\n",
       " 'exclamation, respond.deny': -1.1788264513011688,\n",
       " 'exclamation, respond.agree': -1.4046779338967785,\n",
       " 'exclamation, open.question': -1.6921604875826235,\n",
       " 'exclamation, use.social.convention': -0.4889940897786274,\n",
       " 'exclamation, misc': -1.7419233796251326,\n",
       " 'exclamation, quoted.speech': -1.5635761486194637,\n",
       " 'exclamation, deflection': -1.3741637664050506,\n",
       " 'respond.agree, give.opinion': -1.0515448148414683,\n",
       " 'respond.agree, give.statement': -0.10231777490106037,\n",
       " 'respond.agree, relax.atmosphere': -0.560418357212303,\n",
       " 'respond.agree, closed.question': -0.634471702166014,\n",
       " 'respond.agree, x': -1.356355002800911,\n",
       " 'respond.agree, recall': -2.1179976484521275,\n",
       " 'respond.agree, respond.deny': 0.4087439246476891,\n",
       " 'respond.agree, exclamation': -1.4046779338967785,\n",
       " 'respond.agree, open.question': -0.1124688860772434,\n",
       " 'respond.agree, use.social.convention': -1.2148509531917886,\n",
       " 'respond.agree, misc': -2.0179320382934827,\n",
       " 'respond.agree, quoted.speech': -1.8207691852436458,\n",
       " 'respond.agree, deflection': -0.20689742127823058,\n",
       " 'open.question, give.opinion': -1.5235479035656052,\n",
       " 'open.question, give.statement': 0.20099939485635576,\n",
       " 'open.question, relax.atmosphere': 0.11514493379705423,\n",
       " 'open.question, closed.question': 1.0681971719196177,\n",
       " 'open.question, x': -1.5288902160423954,\n",
       " 'open.question, recall': -2.419114458195377,\n",
       " 'open.question, respond.deny': -0.2189693006010538,\n",
       " 'open.question, exclamation': -1.6921604875826235,\n",
       " 'open.question, respond.agree': -0.1124688860772434,\n",
       " 'open.question, use.social.convention': -0.8618318025096445,\n",
       " 'open.question, misc': -2.21035875950866,\n",
       " 'open.question, quoted.speech': -1.3711561961014367,\n",
       " 'open.question, deflection': -1.484437564337056,\n",
       " 'use.social.convention, give.opinion': -1.587120755005616,\n",
       " 'use.social.convention, give.statement': 0.06169904953965291,\n",
       " 'use.social.convention, relax.atmosphere': -0.07555032343093558,\n",
       " 'use.social.convention, closed.question': -1.3623084823017624,\n",
       " 'use.social.convention, x': -1.8297441027992374,\n",
       " 'use.social.convention, recall': -2.318504923701657,\n",
       " 'use.social.convention, respond.deny': -1.8379559606662978,\n",
       " 'use.social.convention, exclamation': -0.4889940897786274,\n",
       " 'use.social.convention, respond.agree': -1.2148509531917886,\n",
       " 'use.social.convention, open.question': -0.8618318025096445,\n",
       " 'use.social.convention, misc': -1.5574527544963301,\n",
       " 'use.social.convention, quoted.speech': -2.3712542149726152,\n",
       " 'use.social.convention, deflection': -1.9036923145370301,\n",
       " 'misc, give.opinion': -0.8011931628395911,\n",
       " 'misc, give.statement': -2.419022881270522,\n",
       " 'misc, relax.atmosphere': -1.9790499282169394,\n",
       " 'misc, closed.question': -2.068973688731254,\n",
       " 'misc, x': -1.548709208157624,\n",
       " 'misc, recall': -1.3657582748572212,\n",
       " 'misc, respond.deny': -1.9357816537394434,\n",
       " 'misc, exclamation': -1.7419233796251326,\n",
       " 'misc, respond.agree': -2.0179320382934827,\n",
       " 'misc, open.question': -2.21035875950866,\n",
       " 'misc, use.social.convention': -1.5574527544963301,\n",
       " 'misc, quoted.speech': -1.5970760432977729,\n",
       " 'misc, deflection': -1.7752085558833601,\n",
       " 'quoted.speech, give.opinion': -0.548279866499742,\n",
       " 'quoted.speech, give.statement': -2.5346516835351456,\n",
       " 'quoted.speech, relax.atmosphere': -2.2923257903454175,\n",
       " 'quoted.speech, closed.question': -1.7630448360769642,\n",
       " 'quoted.speech, x': -1.3513125231489669,\n",
       " 'quoted.speech, recall': -2.0460816817244223,\n",
       " 'quoted.speech, respond.deny': -2.024701301385798,\n",
       " 'quoted.speech, exclamation': -1.5635761486194637,\n",
       " 'quoted.speech, respond.agree': -1.8207691852436458,\n",
       " 'quoted.speech, open.question': -1.3711561961014367,\n",
       " 'quoted.speech, use.social.convention': -2.3712542149726152,\n",
       " 'quoted.speech, misc': -1.5970760432977729,\n",
       " 'quoted.speech, deflection': -1.4888786440046793,\n",
       " 'deflection, give.opinion': -0.7705444199074922,\n",
       " 'deflection, give.statement': -1.2210821986910982,\n",
       " 'deflection, relax.atmosphere': -1.3388027930736253,\n",
       " 'deflection, closed.question': -1.2221698704821877,\n",
       " 'deflection, x': -1.453542325855465,\n",
       " 'deflection, recall': -2.4280474670924344,\n",
       " 'deflection, respond.deny': 0.30010617155309083,\n",
       " 'deflection, exclamation': -1.3741637664050506,\n",
       " 'deflection, respond.agree': -0.20689742127823058,\n",
       " 'deflection, open.question': -1.484437564337056,\n",
       " 'deflection, use.social.convention': -1.9036923145370301,\n",
       " 'deflection, misc': -1.7752085558833601,\n",
       " 'deflection, quoted.speech': -1.4888786440046793}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_score = sub_scores([test1, test2,test3])\n",
    "s_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kense/.local/lib/python3.6/site-packages/ipykernel_launcher.py:20: RuntimeWarning: divide by zero encountered in log2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "#gut check\n",
    "print(sub_scores([test1, test2]) == sub_scores([test2, test1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note that with very broad categories of labels, there is going to be little defined similarity between each label, and switching the labels will always be bad (thus negative score for all substitutions), however this is expected, and we can see something like, what are the least harmful switches, to show similarity. Notice closed.question and open.question have higher similarity, which is something expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Insertion STEP 4: define Cxy(a) as the count of occurrences of 3-gram xay\n",
    "def occ_count (symbols, cons, grams, gfreq):\n",
    "    assert type(symbols) == list\n",
    "    assert type(grams) == list\n",
    "    assert type(cons) == dict\n",
    "    \n",
    "    o_counts = {}\n",
    "    for a in list(cons.keys()):\n",
    "        for pair in cons[a]:\n",
    "            x = pair.split(\", \")[0]\n",
    "            y = pair.split(\", \")[1]\n",
    "            o_counts[\"{0}, {1}({2})\".format(x,y,a)] = gfreq[\"{0}, {1}, {2}\".format(x,a,y)]\n",
    "    \n",
    "    return o_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a, b(a)': 1, 'a, a(a)': 5}\n"
     ]
    }
   ],
   "source": [
    "#test occ_count with values easily verifiable\n",
    "t1 = [\"a\",\"a\",\"a\",\"a\",\"a\"]\n",
    "t2 = [\"a\",\"a\",\"a\",\"a\",\"b\"]\n",
    "tlog = [t1, t2]\n",
    "symbols = define_symbols(tlog)\n",
    "grams, gfreq = three_grams(tlog)\n",
    "cons = define_context(grams)\n",
    "oc = occ_count(symbols, cons, grams, gfreq)\n",
    "print(oc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Insertion STEP 5: define countRgivenL\n",
    "def countRgL (symbols, ocounts):\n",
    "    assert type(symbols) == list\n",
    "    assert type(ocounts) == dict\n",
    "    \n",
    "    rgl_counts = {}\n",
    "    \n",
    "    for a in symbols:\n",
    "        for x in symbols:\n",
    "            #if a !=x:\n",
    "            total = 0\n",
    "            for k in list(ocounts.keys()):\n",
    "                if k.split(\"(\")[0].split(\", \")[0] == x and k.split(\"(\")[1] == \"{0})\".format(a):\n",
    "                    total += ocounts[k]\n",
    "            rgl_counts[\"{0}/{1}\".format(a,x)] = total\n",
    "    \n",
    "    return rgl_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'b/b': 0, 'b/a': 1, 'a/b': 0, 'a/a': 7}\n",
      "{'b/b': 0, 'b/c': 0, 'b/a': 1, 'c/b': 0, 'c/c': 0, 'c/a': 0, 'a/b': 1, 'a/c': 0, 'a/a': 8}\n"
     ]
    }
   ],
   "source": [
    "#test with values easily verifiable\n",
    "t1 = [\"a\",\"a\",\"a\",\"a\",\"a\",\"a\"]\n",
    "t2 = [\"a\",\"a\",\"a\",\"a\",\"b\",\"a\"]\n",
    "tlog = [t1, t2]\n",
    "symbols = define_symbols(tlog)\n",
    "grams, gfreq = three_grams(tlog)\n",
    "cons = define_context(grams)\n",
    "oc = occ_count(symbols, cons, grams, gfreq)\n",
    "rgl = countRgL(symbols, oc)\n",
    "print(rgl)\n",
    "\n",
    "#should add c to the results table, but no occurrences since it's at the end, opens 1 more for a/b\n",
    "t1 = [\"a\",\"a\",\"a\",\"a\",\"a\",\"a\",\"c\"]\n",
    "t2 = [\"a\",\"a\",\"a\",\"a\",\"b\",\"a\",\"c\"]\n",
    "tlog = [t1, t2]\n",
    "symbols = define_symbols(tlog)\n",
    "grams, gfreq = three_grams(tlog)\n",
    "cons = define_context(grams)\n",
    "oc = occ_count(symbols, cons, grams, gfreq)\n",
    "rgl = countRgL(symbols, oc)\n",
    "print(rgl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Insertion STEP 6: define norm(a)\n",
    "def rgl_norm (symbols, rgl_counts):\n",
    "    assert type(symbols) == list\n",
    "    assert type(rgl_counts) == dict\n",
    "    \n",
    "    rgl_norms = {}\n",
    "    \n",
    "    for a in symbols:\n",
    "        total = 0\n",
    "        for x in symbols:\n",
    "            #if a !=x:\n",
    "            total += rgl_counts[\"{0}/{1}\".format(a,x)]\n",
    "        rgl_norms[\"{0}\".format(a)] = total\n",
    "    \n",
    "    return rgl_norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'b': 1, 'a': 7}\n"
     ]
    }
   ],
   "source": [
    "#test with values easily verifiable\n",
    "t1 = [\"a\",\"a\",\"a\",\"a\",\"a\",\"a\"]\n",
    "t2 = [\"a\",\"a\",\"a\",\"a\",\"b\",\"a\"]\n",
    "tlog = [t1, t2]\n",
    "symbols = define_symbols(tlog)\n",
    "grams, gfreq = three_grams(tlog)\n",
    "cons = define_context(grams)\n",
    "oc = occ_count(symbols, cons, grams, gfreq)\n",
    "rgl = countRgL(symbols, oc)\n",
    "norms = rgl_norm(symbols, rgl)\n",
    "print(norms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Insertion STEP 7: define the probability of all symbols\n",
    "def rgl_prob (trace):\n",
    "    assert type(trace) == list\n",
    "    \n",
    "    p = {}\n",
    "    for item in trace:\n",
    "        for a in item:\n",
    "            try:\n",
    "                p[\"{0}\".format(a)] += 1\n",
    "            except:\n",
    "                p[\"{0}\".format(a)] = 1\n",
    "    \n",
    "    tot_len = 0\n",
    "    for item in trace:\n",
    "        tot_len += len(item)\n",
    "    \n",
    "    for k in list(p.keys()):\n",
    "        p[k] = p[k]/tot_len\n",
    "    \n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 0.9, 'b': 0.1}\n"
     ]
    }
   ],
   "source": [
    "#test with values easily verifiable\n",
    "t1 = [\"a\",\"a\",\"a\",\"a\",\"a\"]\n",
    "t2 = [\"a\",\"a\",\"a\",\"a\",\"b\"]\n",
    "tlog = [t1, t2]\n",
    "symbols = define_symbols(tlog)\n",
    "grams, gfreq = three_grams(tlog)\n",
    "cons = define_context(grams)\n",
    "oc = occ_count(symbols, cons, grams, gfreq)\n",
    "rgl = countRgL(symbols, oc)\n",
    "norms = rgl_norm(symbols, rgl)\n",
    "probs = rgl_prob(tlog)\n",
    "print(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Insertion STEP 8: define rglNorm\n",
    "def normed_counts (symbols, rgl, norms):\n",
    "    assert type(symbols) == list\n",
    "    assert type(rgl) == dict\n",
    "    assert type(norms) == dict\n",
    "    \n",
    "    normed_rgls = {}\n",
    "    \n",
    "    for a in symbols:\n",
    "        for b in symbols:\n",
    "            normed_rgls[\"{0}/{1}\".format(a,b)] = rgl[\"{0}/{1}\".format(a,b)]/norms[\"{0}\".format(a)]\n",
    "    \n",
    "    return normed_rgls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'b/b': 0.0, 'b/a': 1.0, 'a/b': 0.0, 'a/a': 1.0}\n"
     ]
    }
   ],
   "source": [
    "#test with values easily verifiable\n",
    "t1 = [\"a\",\"a\",\"a\",\"a\",\"a\",\"a\"]\n",
    "t2 = [\"a\",\"a\",\"a\",\"a\",\"b\",\"a\"]\n",
    "tlog = [t1, t2]\n",
    "symbols = define_symbols(tlog)\n",
    "grams, gfreq = three_grams(tlog)\n",
    "cons = define_context(grams)\n",
    "oc = occ_count(symbols, cons, grams, gfreq)\n",
    "rgl = countRgL(symbols, oc)\n",
    "norms = rgl_norm(symbols, rgl)\n",
    "probs = rgl_prob(tlog)\n",
    "norm_rgls = normed_counts(symbols, rgl, norms)\n",
    "print(norm_rgls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_scores (traces):\n",
    "    assert type(traces) == list\n",
    "    \n",
    "    symbols = define_symbols(traces)\n",
    "    grams, freq = three_grams(traces)\n",
    "    cons = define_context(grams)\n",
    "    oc = occ_count(symbols, cons, grams, freq)\n",
    "    rgl = countRgL(symbols, oc)\n",
    "    norms = rgl_norm(symbols, rgl)\n",
    "    probs = rgl_prob(traces)\n",
    "    norm_rgls = normed_counts(symbols ,rgl, norms)\n",
    "    \n",
    "    scores = {}\n",
    "    for a in symbols:\n",
    "        for b in symbols:\n",
    "            scores[\"{0}/{1}\".format(a,b)] = np.log2(norm_rgls[\"{0}/{1}\".format(a,b)]/probs[\"{0}\".format(a)]*probs[\"{0}\".format(b)])\n",
    "    \n",
    "    #replace -inf\n",
    "    for k in list(scores.keys()):\n",
    "        if scores[k] == -np.inf:\n",
    "            scores[k] = -1000\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a/a': 0.0}\n",
      "{'b/b': -1000, 'b/a': 3.4594316186372973, 'a/b': -1000, 'a/a': 0.0}\n",
      "{'b/b': -1000, 'b/c': -1000, 'b/a': 1.3219280948873624, 'c/b': 1.0, 'c/c': -1000, 'c/a': -1000, 'a/b': -2.5443205162238103, 'a/c': -1000, 'a/a': -0.8073549220576042}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kense/.local/lib/python3.6/site-packages/ipykernel_launcher.py:16: RuntimeWarning: divide by zero encountered in log2\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "t1 = [\"a\",\"a\",\"a\",\"a\",\"a\",\"a\"]\n",
    "t2 = [\"a\",\"a\",\"a\",\"a\",\"a\",\"a\"]\n",
    "tlog = [t1, t2]\n",
    "print(insert_scores(tlog))\n",
    "\n",
    "t1 = [\"a\",\"a\",\"a\",\"a\",\"a\",\"a\"]\n",
    "t2 = [\"a\",\"a\",\"a\",\"a\",\"b\",\"a\"]\n",
    "tlog = [t1, t2]\n",
    "print(insert_scores(tlog))\n",
    "\n",
    "t1 = [\"a\",\"a\",\"b\",\"a\",\"a\",\"b\",\"c\",\"c\"]\n",
    "t2 = [\"a\",\"a\",\"b\",\"a\",\"a\",\"b\",\"a\",\"a\"]\n",
    "tlog = [t1, t2]\n",
    "print(insert_scores(tlog))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here this seems correct since adding b given a will make t1 more similar to t2, where the only difference is that t2 has an extra b!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kense/.local/lib/python3.6/site-packages/ipykernel_launcher.py:16: RuntimeWarning: divide by zero encountered in log2\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'give.opinion/give.opinion': -0.7252058807037325,\n",
       " 'give.opinion/give.statement': -4.9083757174350895,\n",
       " 'give.opinion/relax.atmosphere': -6.088210604978642,\n",
       " 'give.opinion/closed.question': -8.540568381362702,\n",
       " 'give.opinion/x': -11.949373926930031,\n",
       " 'give.opinion/recall': -4.381951667931271,\n",
       " 'give.opinion/respond.deny': -11.31550182572793,\n",
       " 'give.opinion/exclamation': -11.444784842672895,\n",
       " 'give.opinion/respond.agree': -6.037753179409116,\n",
       " 'give.opinion/open.question': -9.222392421336448,\n",
       " 'give.opinion/use.social.convention': -5.80453990645055,\n",
       " 'give.opinion/misc': -7.467504919172979,\n",
       " 'give.opinion/quoted.speech': -15.029747343394051,\n",
       " 'give.opinion/deflection': -12.942284502143712,\n",
       " 'give.statement/give.opinion': -1.7300799373441995,\n",
       " 'give.statement/give.statement': -1.2152326297635818,\n",
       " 'give.statement/relax.atmosphere': -4.294389567337964,\n",
       " 'give.statement/closed.question': -6.672746762278248,\n",
       " 'give.statement/x': -11.88890722990318,\n",
       " 'give.statement/recall': -5.223081266843426,\n",
       " 'give.statement/respond.deny': -10.295677113198424,\n",
       " 'give.statement/exclamation': -12.746888225030753,\n",
       " 'give.statement/respond.agree': -3.9877282291039124,\n",
       " 'give.statement/open.question': -7.239093584832057,\n",
       " 'give.statement/use.social.convention': -3.8371826138151808,\n",
       " 'give.statement/misc': -8.407038222146129,\n",
       " 'give.statement/quoted.speech': -1000,\n",
       " 'give.statement/deflection': -12.074462883059258,\n",
       " 'relax.atmosphere/give.opinion': -1.472504349495837,\n",
       " 'relax.atmosphere/give.statement': -1.9209883318678223,\n",
       " 'relax.atmosphere/relax.atmosphere': -1.4363868194722773,\n",
       " 'relax.atmosphere/closed.question': -4.9870775223255945,\n",
       " 'relax.atmosphere/x': -9.551161293370836,\n",
       " 'relax.atmosphere/recall': -4.126343429814875,\n",
       " 'relax.atmosphere/respond.deny': -8.957931176666078,\n",
       " 'relax.atmosphere/exclamation': -9.087214193611045,\n",
       " 'relax.atmosphere/respond.agree': -3.5784290315465324,\n",
       " 'relax.atmosphere/open.question': -6.601787366440803,\n",
       " 'relax.atmosphere/use.social.convention': -3.8213647721701967,\n",
       " 'relax.atmosphere/misc': -7.654254786334938,\n",
       " 'relax.atmosphere/quoted.speech': -1000,\n",
       " 'relax.atmosphere/deflection': -10.321679447248068,\n",
       " 'closed.question/give.opinion': -0.3346019249224731,\n",
       " 'closed.question/give.statement': -0.9636581529362797,\n",
       " 'closed.question/relax.atmosphere': -2.1668675488536406,\n",
       " 'closed.question/closed.question': -2.914270125974116,\n",
       " 'closed.question/x': -8.786476192381688,\n",
       " 'closed.question/recall': -2.9466208295468843,\n",
       " 'closed.question/respond.deny': -7.515174170564294,\n",
       " 'closed.question/exclamation': -10.229419688230417,\n",
       " 'closed.question/respond.agree': -3.0309746467780543,\n",
       " 'closed.question/open.question': -5.422064766172813,\n",
       " 'closed.question/use.social.convention': -3.1111274552034263,\n",
       " 'closed.question/misc': -6.4745321860669485,\n",
       " 'closed.question/quoted.speech': -1000,\n",
       " 'closed.question/deflection': -11.141956846980078,\n",
       " 'x/give.opinion': 3.4133210266898217,\n",
       " 'x/give.statement': 0.15748212226023223,\n",
       " 'x/relax.atmosphere': -1.5113908460059409,\n",
       " 'x/closed.question': -0.10125214613993601,\n",
       " 'x/x': -3.8579809951275723,\n",
       " 'x/recall': -1000,\n",
       " 'x/respond.deny': -4.586678973310177,\n",
       " 'x/exclamation': -1000,\n",
       " 'x/respond.agree': -0.25448254296898853,\n",
       " 'x/open.question': -1.3236445674763841,\n",
       " 'x/use.social.convention': -1.2981094753692464,\n",
       " 'x/misc': -0.961074488091676,\n",
       " 'x/quoted.speech': -1000,\n",
       " 'x/deflection': -1000,\n",
       " 'recall/give.opinion': -1.5355988098577633,\n",
       " 'recall/give.statement': -4.018402865413625,\n",
       " 'recall/relax.atmosphere': -5.857200835122111,\n",
       " 'recall/closed.question': -9.032024635977262,\n",
       " 'recall/x': -11.788753484964898,\n",
       " 'recall/recall': -0.6139138744172854,\n",
       " 'recall/respond.deny': -11.517451463147504,\n",
       " 'recall/exclamation': -12.64673448009247,\n",
       " 'recall/respond.agree': -5.600292532085158,\n",
       " 'recall/open.question': -1000,\n",
       " 'recall/use.social.convention': -6.90695387031921,\n",
       " 'recall/misc': -7.084492055871397,\n",
       " 'recall/quoted.speech': -14.64673448009247,\n",
       " 'recall/deflection': -13.55927163884213,\n",
       " 'respond.deny/give.opinion': 2.356143810225275,\n",
       " 'respond.deny/give.statement': 0.6148780786254435,\n",
       " 'respond.deny/relax.atmosphere': -1000,\n",
       " 'respond.deny/closed.question': 1.1634987322828796,\n",
       " 'respond.deny/x': -5.400585038762361,\n",
       " 'respond.deny/recall': -1000,\n",
       " 'respond.deny/respond.deny': -2.807354922057604,\n",
       " 'respond.deny/exclamation': -1000,\n",
       " 'respond.deny/respond.agree': -1.3820490873249334,\n",
       " 'respond.deny/open.question': -2.451211111832329,\n",
       " 'respond.deny/use.social.convention': -1000,\n",
       " 'respond.deny/misc': -1000,\n",
       " 'respond.deny/quoted.speech': -1000,\n",
       " 'respond.deny/deflection': -1000,\n",
       " 'exclamation/give.opinion': 2.807354922057604,\n",
       " 'exclamation/give.statement': 0.4584066132365329,\n",
       " 'exclamation/relax.atmosphere': -0.2104663550296402,\n",
       " 'exclamation/closed.question': -2.3852901558847917,\n",
       " 'exclamation/x': -5.142019004872428,\n",
       " 'exclamation/recall': -1.1766327599537647,\n",
       " 'exclamation/respond.deny': -1000,\n",
       " 'exclamation/exclamation': -2.1926450779423963,\n",
       " 'exclamation/respond.agree': -1000,\n",
       " 'exclamation/open.question': -1000,\n",
       " 'exclamation/use.social.convention': 1.225207436943502,\n",
       " 'exclamation/misc': -1000,\n",
       " 'exclamation/quoted.speech': -1000,\n",
       " 'exclamation/deflection': -5.912537158749661,\n",
       " 'respond.agree/give.opinion': -0.8582161298220561,\n",
       " 'respond.agree/give.statement': -1.9726991850061042,\n",
       " 'respond.agree/relax.atmosphere': -3.7411078268231917,\n",
       " 'respond.agree/closed.question': -1.6625906180483934,\n",
       " 'respond.agree/x': -9.310090397281272,\n",
       " 'respond.agree/recall': -4.929666653083764,\n",
       " 'respond.agree/respond.deny': -10.623750876185033,\n",
       " 'respond.agree/exclamation': -1000,\n",
       " 'respond.agree/respond.agree': -3.628589433121414,\n",
       " 'respond.agree/open.question': -3.660276752210147,\n",
       " 'respond.agree/use.social.convention': -7.335181378244101,\n",
       " 'respond.agree/misc': -1000,\n",
       " 'respond.agree/quoted.speech': -12.753033893129999,\n",
       " 'respond.agree/deflection': -1000,\n",
       " 'open.question/give.opinion': 0.4405725913859815,\n",
       " 'open.question/give.statement': -1.1563032308786751,\n",
       " 'open.question/relax.atmosphere': -1.9507070812287073,\n",
       " 'open.question/closed.question': -2.6780719051126374,\n",
       " 'open.question/x': -1000,\n",
       " 'open.question/recall': -1.9839876820113689,\n",
       " 'open.question/respond.deny': -1000,\n",
       " 'open.question/exclamation': -1000,\n",
       " 'open.question/respond.agree': -1.6507300562998692,\n",
       " 'open.question/open.question': -2.283792966000591,\n",
       " 'open.question/use.social.convention': -2.0269323277869975,\n",
       " 'open.question/misc': -4.859822341951739,\n",
       " 'open.question/quoted.speech': -9.614709844115207,\n",
       " 'open.question/deflection': -1000,\n",
       " 'use.social.convention/give.opinion': -2.363246184235428,\n",
       " 'use.social.convention/give.statement': -2.8966190641939265,\n",
       " 'use.social.convention/relax.atmosphere': -3.4399611503762406,\n",
       " 'use.social.convention/closed.question': -7.614784951231392,\n",
       " 'use.social.convention/x': -10.371513800219027,\n",
       " 'use.social.convention/recall': -4.531658437384224,\n",
       " 'use.social.convention/respond.deny': -11.685174279122789,\n",
       " 'use.social.convention/exclamation': -8.814457296067756,\n",
       " 'use.social.convention/respond.agree': -5.237500631361665,\n",
       " 'use.social.convention/open.question': -9.007102374010152,\n",
       " 'use.social.convention/use.social.convention': -0.8343623569607856,\n",
       " 'use.social.convention/misc': -5.359130075763196,\n",
       " 'use.social.convention/quoted.speech': -1000,\n",
       " 'use.social.convention/deflection': -1000,\n",
       " 'misc/give.opinion': -1.172163473638312,\n",
       " 'misc/give.statement': -4.044673738516396,\n",
       " 'misc/relax.atmosphere': -6.2985092075037254,\n",
       " 'misc/closed.question': -7.88837050763772,\n",
       " 'misc/x': -1000,\n",
       " 'misc/recall': -2.9792733935656015,\n",
       " 'misc/respond.deny': -1000,\n",
       " 'misc/exclamation': -1000,\n",
       " 'misc/respond.agree': -1000,\n",
       " 'misc/open.question': -8.695725429695324,\n",
       " 'misc/use.social.convention': -4.277872914809427,\n",
       " 'misc/misc': -0.4083428467048356,\n",
       " 'misc/quoted.speech': -1000,\n",
       " 'misc/deflection': -1000,\n",
       " 'quoted.speech/give.opinion': 5.39231742277876,\n",
       " 'quoted.speech/give.statement': 2.8734441125153767,\n",
       " 'quoted.speech/relax.atmosphere': -1000,\n",
       " 'quoted.speech/closed.question': -1000,\n",
       " 'quoted.speech/x': -1000,\n",
       " 'quoted.speech/recall': 2.823367240046235,\n",
       " 'quoted.speech/respond.deny': -1000,\n",
       " 'quoted.speech/exclamation': -1000,\n",
       " 'quoted.speech/respond.agree': 1.8765169465649998,\n",
       " 'quoted.speech/open.question': -1000,\n",
       " 'quoted.speech/use.social.convention': 2.4178525148858983,\n",
       " 'quoted.speech/misc': -1000,\n",
       " 'quoted.speech/quoted.speech': -3.0,\n",
       " 'quoted.speech/deflection': -1000,\n",
       " 'deflection/give.opinion': 3.2173917402780816,\n",
       " 'deflection/give.statement': 0.6985184300146979,\n",
       " 'deflection/relax.atmosphere': -1000,\n",
       " 'deflection/closed.question': 2.761712256501892,\n",
       " 'deflection/x': -3.3169446873731068,\n",
       " 'deflection/recall': -1000,\n",
       " 'deflection/respond.deny': -1000,\n",
       " 'deflection/exclamation': -1000,\n",
       " 'deflection/respond.agree': -1000,\n",
       " 'deflection/open.question': -1.3675707604430747,\n",
       " 'deflection/use.social.convention': -1000,\n",
       " 'deflection/misc': -1000,\n",
       " 'deflection/quoted.speech': -1000,\n",
       " 'deflection/deflection': -4.087462841250339}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test on our logs, specifically looking for respond.agree, open.question or respond.agree, closed.question to have high scores, since they usually\n",
    "#appear next to each other in that order\n",
    "ins_score = insert_scores([test1,test2,test3])\n",
    "ins_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scores generally make sense\n",
    "\n",
    "# we can define similarity function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kense/.local/lib/python3.6/site-packages/ipykernel_launcher.py:16: RuntimeWarning: divide by zero encountered in log2\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#gutcheck\n",
    "insert_scores([test1,test2]) == insert_scores([test2, test1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_cost(cost):\n",
    "    #convert cost to a distance penalty\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_similarity(trace1, trace2, sub_cost, ins_cost, probs):\n",
    "    \n",
    "    assert type(trace1) == type(trace2) == list\n",
    "    \n",
    "    #pad traces\n",
    "    trace1 = [\"_\"] + trace1\n",
    "    trace2 = [\"_\"] + trace2\n",
    "    \n",
    "    #set shorter one as tr1\n",
    "    if len(trace1) > len(trace2):\n",
    "        copy = trace1\n",
    "        trace1 = trace2\n",
    "        trace2 = copy\n",
    "\n",
    "    M = len(trace1)\n",
    "    N = len(trace2)\n",
    "    sim_table = np.zeros((M,N)) #establish table\n",
    "    s_score = sub_cost #get substitution score\n",
    "    ins_score = ins_cost #get insertion score\n",
    "    p = probs #get probabilities\n",
    "    \n",
    "    #fill table, horizontal -> vertical\n",
    "    for i in range(M):\n",
    "        for j in range(N):\n",
    "            \n",
    "            #original fill horizontal\n",
    "            if i == 0:\n",
    "                if j == 0: #first fill\n",
    "                    sim_table[i][j] = 1000\n",
    "                elif j == 1: #first insert\n",
    "                    sim_table[i][j] = p[\"{0}\".format(trace2[j])]\n",
    "                else: #rest fill, base insert scores\n",
    "                    sim_table[i][j] = ins_score[\"{0}/{1}\".format(trace2[j], trace2[j-1])] + sim_table[i][j-1]\n",
    "            \n",
    "            #original fill vertical\n",
    "            elif j == 0:\n",
    "                if i == 0:#first fill\n",
    "                    sim_table[i][j] = 1000\n",
    "                elif i == 1:\n",
    "                    sim_table[i][j] = p[\"{0}\".format(trace1[i])]\n",
    "                else: #rest fill, base is the opposite of insert scores\n",
    "                    sim_table[i][j] = -1*ins_score[\"{0}/{1}\".format(trace1[i], trace1[i-1])] + sim_table[i-1][j]\n",
    "            \n",
    "            elif trace1[i] == trace2[j]: #no changes\n",
    "                sim_table[i][j] = sim_table[i-1][j-1]\n",
    "            \n",
    "            else: #substitution, insertion or deletion\n",
    "                \n",
    "                #determine the min\n",
    "                op = np.argmax([sim_table[i-1][j], sim_table[i][j-1], sim_table[i-1][j-1]]) #in order, removal, insertion, substitution\n",
    "                if op == 0:\n",
    "                    sim_table[i][j] = -1 + sim_table[i-1][j]#-1*ins_score[\"{0}/{1}\".format(trace2[j],trace1[i])] + sim_table[i-1][j] #removal\n",
    "                elif op == 1:\n",
    "                    sim_table[i][j] = ins_score[\"{0}/{1}\".format(trace2[j],trace1[i])] + sim_table[i][j-1] #insertion\n",
    "                elif op == 2:\n",
    "                    sim_table[i][j] = s_score[\"{0}, {1}\".format(trace1[i],trace2[j])] + sim_table[i-1][j-1] #substitution\n",
    "                \n",
    "    return sim_table[i][j] #final score\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "992.8561183322523\n",
      "1000.0\n"
     ]
    }
   ],
   "source": [
    "t1 = [\"a\",\"a\",\"b\",\"a\",\"a\",\"b\",\"c\",\"c\"]\n",
    "t2 = [\"a\",\"a\",\"b\",\"a\",\"a\",\"b\",\"a\",\"a\"]\n",
    "t3 = [\"a\",\"a\",\"a\",\"a\",\"b\",\"c\",\"c\",\"c\",\"c\",\"c\"]\n",
    "t4 = [\"a\",\"a\",\"a\"]\n",
    "t5 = [\"b\",\"b\",\"a\",\"b\"]\n",
    "t6 = [\"c\",\"b\",\"b\",\"b\",\"b\",\"c\",\"b\",\"c\",\"c\",\"b\",\"a\",\"b\",\"c\",\"c\",\"a\",\"a\",\"b\",\"c\"]\n",
    "t7 = [\"c\",\"c\",\"c\",\"c\",\"c\",\"c\",\"c\",\"a\",\"a\",\"b\"]\n",
    "t8 = [\"c\",\"c\",\"c\",\"c\"]\n",
    "t9 = [\"b\",\"a\",\"a\",\"b\",\"a\",\"a\",\"b\",\"c\"]\n",
    "t10 = [\"a\",\"c\",\"c\",\"b\",\"a\",\"c\",\"c\",\"b\"]\n",
    "tset = [t1,t2,t3,t4,t5,t6,t7,t8,t9,t10]\n",
    "ssc = sub_scores(tset)\n",
    "insc = insert_scores(tset)\n",
    "prob = rgl_prob(tset)\n",
    "\n",
    "a = [\"a\",\"c\",\"c\",\"b\",\"b\",\"a\",\"b\",\"b\",\"c\",\"c\"]\n",
    "b = [\"b\",\"c\",\"c\",\"a\",\"a\",\"a\",\"c\",\"c\",\"a\",\"b\",\"b\"]\n",
    "c = [\"a\",\"c\",\"c\",\"b\",\"b\",\"a\",\"b\",\"b\",\"c\",\"c\"]\n",
    "sim1 = calc_similarity(a,b,ssc,insc,prob)\n",
    "sim2 = calc_similarity(a,c,ssc,insc,prob)\n",
    "print(sim1)\n",
    "print(sim2) #we'll have to account for the fact that 0 is a special case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kense/.local/lib/python3.6/site-packages/ipykernel_launcher.py:16: RuntimeWarning: divide by zero encountered in log2\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "tset1 = [test1, test2, test3]\n",
    "ssc1 = sub_scores(tset1)\n",
    "insc1 = insert_scores(tset1)\n",
    "prob1 = rgl_prob(tset1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "420.0001200798307\n",
      "-156.00760062508994\n"
     ]
    }
   ],
   "source": [
    "sim3 = calc_similarity(test1, test2, ssc1, insc1, prob1)\n",
    "sim4 = calc_similarity(test1, test3, ssc1, insc1, prob1)\n",
    "print(sim3)\n",
    "print(sim4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# indeed, trace1 should be closer to trace2 than it is to trace3!\n",
    "\n",
    "# Next, we can consider things like defined sub-conversations (trends of labels that are predetermined) and their frequencies. The intuition being that traces with similar label occurrences only address short term connections rather than long term trends, adding freq for long term trends should also assist in telling us if the \"genre\" or the \"flow\" of two traces are similar, which is also a valuable metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_similarity2(trace1, trace2, sub_cost, ins_cost, probs):\n",
    "    \n",
    "    assert type(trace1) == type(trace2) == list\n",
    "    \n",
    "    #pad traces\n",
    "    trace1 = [\"_\"] + trace1\n",
    "    trace2 = [\"_\"] + trace2\n",
    "\n",
    "    M = len(trace1)\n",
    "    N = len(trace2)\n",
    "    sim_table = np.zeros((M,N)) #establish table\n",
    "    s_score = sub_cost #get substitution score\n",
    "    ins_score = ins_cost #get insertion score\n",
    "    p = probs #get probabilities\n",
    "    \n",
    "    #fill table, horizontal -> vertical\n",
    "    for i in range(M):\n",
    "        for j in range(N):\n",
    "            \n",
    "            #original fill horizontal\n",
    "            if i == 0:\n",
    "                if j == 0: #first fill\n",
    "                    sim_table[i][j] = 1000\n",
    "                elif j == 1: #first insert\n",
    "                    sim_table[i][j] = p[\"{0}\".format(trace2[j])]\n",
    "                else: #rest fill, base insert scores\n",
    "                    sim_table[i][j] = ins_score[\"{0}/{1}\".format(trace2[j], trace2[j-1])] + sim_table[i][j-1]\n",
    "            \n",
    "            #original fill vertical\n",
    "            elif j == 0:\n",
    "                if i == 0:#first fill\n",
    "                    sim_table[i][j] = 1000\n",
    "                elif i == 1:\n",
    "                    sim_table[i][j] = p[\"{0}\".format(trace1[i])]\n",
    "                else: #rest fill, base is the opposite of insert scores\n",
    "                    sim_table[i][j] = -1*ins_score[\"{0}/{1}\".format(trace1[i], trace1[i-1])] + sim_table[i-1][j]\n",
    "            \n",
    "            elif trace1[i] == trace2[j]: #no changes\n",
    "                sim_table[i][j] = sim_table[i-1][j-1]\n",
    "            \n",
    "            else: #substitution, insertion or deletion\n",
    "                \n",
    "                #determine the min\n",
    "                op = np.argmax([sim_table[i-1][j], sim_table[i][j-1], sim_table[i-1][j-1]]) #in order, removal, insertion, substitution\n",
    "                if op == 0:\n",
    "                    sim_table[i][j] = -1 + sim_table[i-1][j]#-1*ins_score[\"{0}/{1}\".format(trace2[j],trace1[i])] + sim_table[i-1][j] #removal\n",
    "                elif op == 1:\n",
    "                    sim_table[i][j] = ins_score[\"{0}/{1}\".format(trace2[j],trace1[i])] + sim_table[i][j-1] #insertion\n",
    "                elif op == 2:\n",
    "                    sim_table[i][j] = s_score[\"{0}, {1}\".format(trace1[i],trace2[j])] + sim_table[i-1][j-1] #substitution\n",
    "                \n",
    "    return sim_table[i][j] #final score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "585.5541655852008\n",
      "420.0001200798307\n",
      "-156.00760062508994\n",
      "1366.7683979683766\n"
     ]
    }
   ],
   "source": [
    "sim3 = calc_similarity2(test1, test2, ssc1, insc1, prob1)\n",
    "sim4 = calc_similarity2(test2, test1, ssc1, insc1, prob1)\n",
    "sim5 = calc_similarity2(test1, test3, ssc1, insc1, prob1)\n",
    "sim6 = calc_similarity2(test3, test1, ssc1, insc1, prob1)\n",
    "print(sim3)\n",
    "print(sim4)\n",
    "print(sim5)\n",
    "print(sim6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "497.2228571674842\n",
      "761.3879992967333\n"
     ]
    }
   ],
   "source": [
    "print(((1000-sim3)+(1000-sim4))/2)\n",
    "print(((1000-sim5)+(sim6-1000))/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1074 939 1322\n"
     ]
    }
   ],
   "source": [
    "print(len(test1), len(test2), len(test3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
