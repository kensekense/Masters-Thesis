{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper function to count the occurrences of violations to the label\n",
    "def count_label (sub, labels):\n",
    "    assert type(sub) == list\n",
    "    assert type(labels) == list\n",
    "    \n",
    "    count = 0\n",
    "    for item in sub:\n",
    "        if item not in labels:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "#until-N definition\n",
    "def until_N (trace, x, y, N):\n",
    "    \n",
    "    assert type(trace) == list\n",
    "    assert type(x) == list\n",
    "    assert type(y) == list\n",
    "    \n",
    "    sol = []\n",
    "    current = N\n",
    "    s = -1\n",
    "    e = -1\n",
    "    for i in range(len(trace)):\n",
    "        \n",
    "        if (trace[i] in x) and e == -1 and s == -1: #finding first instance of x\n",
    "            s = i\n",
    "        \n",
    "        if (s != -1) and (trace[i] not in x) and (trace[i] not in y): #started count and violates Until\n",
    "            \n",
    "            if current <= 0: #no more N to give\n",
    "                s = -1\n",
    "                e = -1\n",
    "                current = N\n",
    "                continue #search for next\n",
    "                \n",
    "            else: #more N to give, decrement\n",
    "                current -= 1\n",
    "        \n",
    "        if s != -1 and (trace[i] in y): #found instance of y and x\n",
    "            e = i\n",
    "            sol.append((s,e, count_label(trace[s:e],x), e-s)) #append starting and ending index, with number of appearances of x\n",
    "            s = -1\n",
    "            e = -1\n",
    "    \n",
    "    return sol\n",
    "\n",
    "#STEPS for Substitution Score\n",
    "\n",
    "#STEP 1: Define the symbols in the list of traces\n",
    "def define_symbols (traces):\n",
    "    assert type(traces) == list\n",
    "    symbols = []\n",
    "    for item in traces:\n",
    "        symbols.append(set(item))\n",
    "    x = symbols[0]\n",
    "    for i in range(len(symbols)):\n",
    "        x = x.union(symbols[i])\n",
    "    \n",
    "    return list(x)\n",
    "\n",
    "\n",
    "#STEP 2: Define the set of all 3-grams in the logs and their frequencies\n",
    "def three_grams (traces):\n",
    "    assert type(traces) == list\n",
    "    g3 = []\n",
    "    g3_freq = {}\n",
    "    for trace in traces:\n",
    "        for i in range(len(trace)-2):\n",
    "            g3.append(\", \".join(list(trace[i:i+3])))\n",
    "            try:\n",
    "                g3_freq[\", \".join(list(trace[i:i+3]))] += 1\n",
    "            except:\n",
    "                g3_freq[\", \".join(list(trace[i:i+3]))] = 1\n",
    "    return list(set(g3)), g3_freq\n",
    "\n",
    "\n",
    "#STEP 3: Define the context for symbol a\n",
    "def define_context(grams):\n",
    "    \n",
    "    assert type(grams) == list\n",
    "    \n",
    "    context = {}\n",
    "    for gram in grams:\n",
    "        x,a,y = gram.split(\", \")\n",
    "        try:\n",
    "            context[a].append(\"{0}, {1}\".format(x,y))\n",
    "        except:\n",
    "            context[a] = []\n",
    "            context[a].append(\"{0}, {1}\".format(x,y))\n",
    "            \n",
    "    #clear dups\n",
    "    for k in list(context.keys()):\n",
    "        context[k] = list(set(context[k]))\n",
    "    \n",
    "    return context\n",
    "\n",
    "\n",
    "#STEP 4: define pairs of context\n",
    "def context_pairs (context):\n",
    "    \n",
    "    assert type(context) == dict\n",
    "    \n",
    "    context_pairs = {}\n",
    "    for a in list(context.keys()):\n",
    "        for b in list(context.keys()):\n",
    "            if a != b:\n",
    "                context_pairs[\"{0}, {1}\".format(a, b)] = list(set(context[a]).intersection(set(context[b])))\n",
    "    \n",
    "    return context_pairs\n",
    "\n",
    "\n",
    "#STEP 5: define co-occurrence combinations\n",
    "def define_cooccurrence(symbols, context_pairs, gram_freq):\n",
    "    \n",
    "    assert type(context_pairs) == dict\n",
    "    assert type(gram_freq) == dict\n",
    "    assert type(symbols) == list\n",
    "    \n",
    "    co_occur = {}\n",
    "    for k in list(context_pairs.keys()):\n",
    "        for item in context_pairs[k]:\n",
    "            for a in symbols:\n",
    "                for b in symbols:\n",
    "                    x,y = item.split(\", \")[0], item.split(\", \")[1]\n",
    "                    if a == b:\n",
    "                        try:\n",
    "                            n = gram_freq[\"{0}, {1}, {2}\".format(x,a,y)]\n",
    "                            co_occur[\"{0}, {1}({2}, {3})\".format(x,y,a,b)] = (n*(n-1))/2\n",
    "                        except:\n",
    "                            co_occur[\"{0}, {1}({2}, {3})\".format(x,y,a,b)] = 0.0\n",
    "                        \n",
    "                    elif a != b:\n",
    "                        try:\n",
    "                            n_i = gram_freq[\"{0}, {1}, {2}\".format(x,a,y)]\n",
    "                            n_j = gram_freq[\"{0}, {1}, {2}\".format(x,b,y)]\n",
    "                            co_occur[\"{0}, {1}({2}, {3})\".format(x,y,a,b)] = n_i*n_j\n",
    "                        except:\n",
    "                            co_occur[\"{0}, {1}({2}, {3})\".format(x,y,a,b)] = 0.0\n",
    "    \n",
    "    return co_occur\n",
    "\n",
    "\n",
    "#STEP 6: Define the count of co-occurrences for symbols a,b for all contexts\n",
    "def co_occur_combos(symbols, con_pairs, co_occurs):\n",
    "    assert type(symbols) == list\n",
    "    assert type(con_pairs) == dict\n",
    "    assert type(co_occurs) == dict\n",
    "    \n",
    "    co_occur_combos = {}\n",
    "    for a in symbols:\n",
    "        for b in symbols:\n",
    "            total = 0.0\n",
    "            for k in list(con_pairs.keys()):\n",
    "                for item in con_pairs[k]:\n",
    "                    total += co_occurs[\"{0}({1}, {2})\".format(item,a,b)]\n",
    "            co_occur_combos[\"{0}, {1}\".format(a,b)] = total\n",
    "    \n",
    "    return co_occur_combos\n",
    "\n",
    "\n",
    "#STEP 7: Define norm on the count of co-occur combos\n",
    "def define_norm (co_combos):\n",
    "    assert type(co_combos) == dict\n",
    "    norm = 0.0\n",
    "    for k in list(co_combos.keys()):\n",
    "        norm += co_combos[k]\n",
    "    \n",
    "    return norm\n",
    "\n",
    "\n",
    "#STEP 8: Define matrix M over A x A\n",
    "def define_matrix (symbols, co_combos, norm):\n",
    "    assert type(symbols) == list\n",
    "    assert type(co_combos) == dict\n",
    "    assert type(norm) == float\n",
    "    \n",
    "    mat_M = {}\n",
    "    for a in symbols:\n",
    "        for b in symbols:\n",
    "            mat_M[\"{0}, {1}\".format(a,b)] = co_combos[\"{0}, {1}\".format(a,b)]/norm\n",
    "    \n",
    "    return mat_M\n",
    "\n",
    "\n",
    "#STEP 9: Define the probability of occurrence\n",
    "def prob_occur (symbols, mat_M):\n",
    "    assert type(symbols) == list\n",
    "    assert type(mat_M) == dict\n",
    "    \n",
    "    p = {}\n",
    "    for a in symbols:\n",
    "        total = 0\n",
    "        for b in symbols:\n",
    "            if a != b:\n",
    "                total += mat_M[\"{0}, {1}\".format(a,b)]\n",
    "        total += mat_M[\"{0}, {1}\".format(a,a)]\n",
    "        p[\"{0}\".format(a)] = total\n",
    "    \n",
    "    return p\n",
    "\n",
    "\n",
    "#STEP 10: Define the expected values\n",
    "def exp_val (symbols, prob):\n",
    "    assert type(symbols) == list\n",
    "    assert type(prob) == dict\n",
    "    \n",
    "    e_val = {}\n",
    "    for a in symbols:\n",
    "        for b in symbols:\n",
    "            if a == b:\n",
    "                e_val[\"{0}, {1}\".format(a,b)] = prob[\"{0}\".format(a)]**2\n",
    "            else:\n",
    "                e_val[\"{0}, {1}\".format(a,b)] = 2*prob[\"{0}\".format(a)]*prob[\"{0}\".format(b)]\n",
    "    \n",
    "    return e_val\n",
    "\n",
    "\n",
    "#STEP 11: Define the function for substitution scores\n",
    "def sub_scores (traces):\n",
    "    assert type(traces) == list\n",
    "    \n",
    "    symbols = define_symbols(traces)\n",
    "    three_gs, three_gs_freq = three_grams(traces)\n",
    "    cons = define_context(three_gs)\n",
    "    con_pairs = context_pairs(cons)\n",
    "    co_occurs = define_cooccurrence(symbols, con_pairs, three_gs_freq)\n",
    "    co_combos = co_occur_combos(symbols, con_pairs, co_occurs)\n",
    "    norm = define_norm(co_combos)\n",
    "    matM = define_matrix(symbols, co_combos, norm)\n",
    "    probs = prob_occur(symbols, matM)\n",
    "    e_val = exp_val(symbols, probs)\n",
    "    \n",
    "    sub_costs = {}\n",
    "    for a in symbols:\n",
    "        for b in symbols:\n",
    "            if a!=b:\n",
    "                try:\n",
    "                    sub_costs[\"{0}, {1}\".format(a,b)] = np.log2(matM[\"{0}, {1}\".format(a,b)]/e_val[\"{0}, {1}\".format(a,b)])\n",
    "                except:\n",
    "                    sub_costs[\"{0}, {1}\".format(a,b)] = -1000\n",
    "    \n",
    "    return sub_costs\n",
    "\n",
    "#STEPS 1-3 are the same for Insertion Score\n",
    "\n",
    "#STEP 4: Define occurence of 3-gram counts\n",
    "def occ_count (symbols, cons, grams, gfreq):\n",
    "    assert type(symbols) == list\n",
    "    assert type(grams) == list\n",
    "    assert type(cons) == dict\n",
    "    \n",
    "    o_counts = {}\n",
    "    for a in list(cons.keys()):\n",
    "        for pair in cons[a]:\n",
    "            x = pair.split(\", \")[0]\n",
    "            y = pair.split(\", \")[1]\n",
    "            o_counts[\"{0}, {1}({2})\".format(x,y,a)] = gfreq[\"{0}, {1}, {2}\".format(x,a,y)]\n",
    "    \n",
    "    return o_counts\n",
    "\n",
    "\n",
    "#STEP 5: define countRgivenL\n",
    "def countRgL (symbols, ocounts):\n",
    "    assert type(symbols) == list\n",
    "    assert type(ocounts) == dict\n",
    "    \n",
    "    rgl_counts = {}\n",
    "    \n",
    "    for a in symbols:\n",
    "        for x in symbols:\n",
    "            #if a !=x:\n",
    "            total = 0\n",
    "            for k in list(ocounts.keys()):\n",
    "                if k.split(\"(\")[0].split(\", \")[0] == x and k.split(\"(\")[1] == \"{0})\".format(a):\n",
    "                    total += ocounts[k]\n",
    "            rgl_counts[\"{0}/{1}\".format(a,x)] = total\n",
    "    \n",
    "    return rgl_counts\n",
    "\n",
    "\n",
    "#STEP 6: define norm(a)\n",
    "def rgl_norm (symbols, rgl_counts):\n",
    "    assert type(symbols) == list\n",
    "    assert type(rgl_counts) == dict\n",
    "    \n",
    "    rgl_norms = {}\n",
    "    \n",
    "    for a in symbols:\n",
    "        total = 0\n",
    "        for x in symbols:\n",
    "            #if a !=x:\n",
    "            total += rgl_counts[\"{0}/{1}\".format(a,x)]\n",
    "        rgl_norms[\"{0}\".format(a)] = total\n",
    "    \n",
    "    return rgl_norms\n",
    "\n",
    "\n",
    "#STEP 7: define the probability of all symbols\n",
    "def rgl_prob (trace):\n",
    "    assert type(trace) == list\n",
    "    \n",
    "    p = {}\n",
    "    for item in trace:\n",
    "        for a in item:\n",
    "            try:\n",
    "                p[\"{0}\".format(a)] += 1\n",
    "            except:\n",
    "                p[\"{0}\".format(a)] = 1\n",
    "    \n",
    "    tot_len = 0\n",
    "    for item in trace:\n",
    "        tot_len += len(item)\n",
    "    \n",
    "    for k in list(p.keys()):\n",
    "        p[k] = p[k]/tot_len\n",
    "    \n",
    "    return p\n",
    "\n",
    "\n",
    "#STEP 8: define rglNorm\n",
    "def normed_counts (symbols, rgl, norms):\n",
    "    assert type(symbols) == list\n",
    "    assert type(rgl) == dict\n",
    "    assert type(norms) == dict\n",
    "    \n",
    "    normed_rgls = {}\n",
    "    \n",
    "    for a in symbols:\n",
    "        for b in symbols:\n",
    "            normed_rgls[\"{0}/{1}\".format(a,b)] = rgl[\"{0}/{1}\".format(a,b)]/norms[\"{0}\".format(a)]\n",
    "    \n",
    "    return normed_rgls\n",
    "\n",
    "\n",
    "#STEP 9: Define the function for insertion score\n",
    "def insert_scores (traces):\n",
    "    assert type(traces) == list\n",
    "    \n",
    "    symbols = define_symbols(traces)\n",
    "    grams, freq = three_grams(traces)\n",
    "    cons = define_context(grams)\n",
    "    oc = occ_count(symbols, cons, grams, freq)\n",
    "    rgl = countRgL(symbols, oc)\n",
    "    norms = rgl_norm(symbols, rgl)\n",
    "    probs = rgl_prob(traces)\n",
    "    norm_rgls = normed_counts(symbols ,rgl, norms)\n",
    "    \n",
    "    scores = {}\n",
    "    for a in symbols:\n",
    "        for b in symbols:\n",
    "            scores[\"{0}/{1}\".format(a,b)] = np.log2(norm_rgls[\"{0}/{1}\".format(a,b)]/probs[\"{0}\".format(a)]*probs[\"{0}\".format(b)])\n",
    "    \n",
    "    #replace -inf\n",
    "    for k in list(scores.keys()):\n",
    "        if scores[k] == -np.inf:\n",
    "            scores[k] = -1000\n",
    "    \n",
    "    return scores\n",
    "\n",
    "#function definition for calculating similarity\n",
    "def calc_similarity(trace1, trace2, sub_cost, ins_cost, probs):\n",
    "    \n",
    "    assert type(trace1) == type(trace2) == list\n",
    "    \n",
    "    #pad traces\n",
    "    trace1 = [\"_\"] + trace1\n",
    "    trace2 = [\"_\"] + trace2\n",
    "    \n",
    "    #set shorter one as tr1\n",
    "    if len(trace1) > len(trace2):\n",
    "        copy = trace1\n",
    "        trace1 = trace2\n",
    "        trace2 = copy\n",
    "\n",
    "    M = len(trace1)\n",
    "    N = len(trace2)\n",
    "    sim_table = np.zeros((M,N)) #establish table\n",
    "    s_score = sub_cost #get substitution score\n",
    "    ins_score = ins_cost #get insertion score\n",
    "    p = probs #get probabilities\n",
    "    \n",
    "    #fill table, horizontal -> vertical\n",
    "    for i in range(M):\n",
    "        for j in range(N):\n",
    "            \n",
    "            #original fill horizontal\n",
    "            if i == 0:\n",
    "                if j == 0: #first fill\n",
    "                    sim_table[i][j] = 1000\n",
    "                elif j == 1: #first insert\n",
    "                    sim_table[i][j] = p[\"{0}\".format(trace2[j])]\n",
    "                else: #rest fill, base insert scores\n",
    "                    sim_table[i][j] = ins_score[\"{0}/{1}\".format(trace2[j], trace2[j-1])] + sim_table[i][j-1]\n",
    "            \n",
    "            #original fill vertical\n",
    "            elif j == 0:\n",
    "                if i == 0:#first fill\n",
    "                    sim_table[i][j] = 1000\n",
    "                elif i == 1:\n",
    "                    sim_table[i][j] = p[\"{0}\".format(trace1[i])]\n",
    "                else: #rest fill, base is the opposite of insert scores\n",
    "                    sim_table[i][j] = -1*ins_score[\"{0}/{1}\".format(trace1[i], trace1[i-1])] + sim_table[i-1][j]\n",
    "            \n",
    "            elif trace1[i] == trace2[j]: #no changes\n",
    "                sim_table[i][j] = sim_table[i-1][j-1]\n",
    "            \n",
    "            else: #substitution, insertion or deletion\n",
    "                \n",
    "                #determine the min\n",
    "                op = np.argmax([sim_table[i-1][j], sim_table[i][j-1], sim_table[i-1][j-1]]) #in order, removal, insertion, substitution\n",
    "                if op == 0:\n",
    "                    sim_table[i][j] = -1 + sim_table[i-1][j]#-1*ins_score[\"{0}/{1}\".format(trace2[j],trace1[i])] + sim_table[i-1][j] #removal\n",
    "                elif op == 1:\n",
    "                    sim_table[i][j] = ins_score[\"{0}/{1}\".format(trace2[j],trace1[i])] + sim_table[i][j-1] #insertion\n",
    "                elif op == 2:\n",
    "                    sim_table[i][j] = s_score[\"{0}, {1}\".format(trace1[i],trace2[j])] + sim_table[i-1][j-1] #substitution\n",
    "                \n",
    "    return sim_table[i][j] #final score\n",
    "\n",
    "#define the function to find all relevant sub-conversations in a trace\n",
    "def find_sub_conversations (trace, labels, c_cap, l):\n",
    "    assert type(trace) == list\n",
    "    assert type(labels) == list\n",
    "    assert type(c_cap) == float\n",
    "    assert type(l) == int\n",
    "    \n",
    "    #counts\n",
    "    sub_convos = {}\n",
    "    \n",
    "    #cycle through label pairs\n",
    "    for i in range(len(labels)):\n",
    "        for j in range(len(labels)):\n",
    "            \n",
    "            if i != j: #no repeats\n",
    "                candidate = until_N(trace, [labels[i]], [labels[j]], 50) #cap at 50\n",
    "                sub_convos[\"{0} -> {1}\".format(labels[i], labels[j])] = [0,[]] #record all possible\n",
    "                \n",
    "                for item in candidate:\n",
    "                    if item[3] > 10 and item [3] < l and item[2] < item[3]*c_cap:\n",
    "                        sub_convos[\"{0} -> {1}\".format(labels[i], labels[j])][0] += 1\n",
    "                        sub_convos[\"{0} -> {1}\".format(labels[i], labels[j])][1].append(item)\n",
    "\n",
    "    return sub_convos\n",
    "\n",
    "#weighting function\n",
    "def calc_weights(trace, sub_convos):\n",
    "    \n",
    "    assert type(trace) == list #takes a list of traces, i.e: event log\n",
    "    \n",
    "    tw_id = {}\n",
    "    center = len(trace)//2\n",
    "    tf = {}\n",
    "    idf = {}\n",
    "    N = 0 #track number of sub_convos\n",
    "\n",
    "    #instantiate tf and idf values\n",
    "    for i in range(len(trace)):\n",
    "        tf[i] = 0\n",
    "        idf[i] = 0\n",
    "\n",
    "    #find non-zero from sub_convos table to fill tf and idf table\n",
    "    for key in list(sub_convos.keys()):\n",
    "        if sub_convos[key][0] != 0:\n",
    "            N += 1\n",
    "            for entry in sub_convos[key][1]: #for each entry\n",
    "                s = entry[0]\n",
    "                e = entry[1]\n",
    "                label1, label2 = key.split(\" -> \")\n",
    "\n",
    "                for i in range(s,e):\n",
    "                    if trace[i] == label1 or trace[i] == label2:\n",
    "                        tf[i] += 1\n",
    "                    else:\n",
    "                        idf[i] += 1\n",
    "\n",
    "    #apply log onto idf vals\n",
    "    for i in range(len(idf)):\n",
    "        try:\n",
    "            if idf[i] == 0:\n",
    "                idf[i] = 0\n",
    "            else:\n",
    "                idf[i] = np.log2(N/idf[i])\n",
    "        except:\n",
    "            idf[i] = 0\n",
    "\n",
    "    #calculate weights\n",
    "    for i in range(len(trace)):\n",
    "        if center == i:\n",
    "            tw_id[i] = 1 + (tf[i]*idf[i]) #center\n",
    "        else:\n",
    "            tw_id[i] = (1/np.abs(center-i)) + (tf[i]*idf[i]) #w_i + tf-idf(a_i)\n",
    "\n",
    "    #convert to list\n",
    "    trace_weights = []\n",
    "    for k in list(tw_id.keys()):\n",
    "        trace_weights.append(tw_id[k])\n",
    "        \n",
    "    return trace_weights\n",
    "\n",
    "#function for similarity score via weights\n",
    "def weight_similarity (trace1, trace2):\n",
    "    \n",
    "    assert type(trace1) == type(trace2) == list\n",
    "    \n",
    "    #pad traces\n",
    "    trace1 = [\"_\"] + trace1\n",
    "    trace2 = [\"_\"] + trace2\n",
    "    \n",
    "    #set shorter one as tr1\n",
    "    if len(trace1) > len(trace2):\n",
    "        copy = trace1\n",
    "        trace1 = trace2\n",
    "        trace2 = copy\n",
    "\n",
    "    M = len(trace1)\n",
    "    N = len(trace2)\n",
    "    sim_table = np.zeros((M,N)) #establish table\n",
    "    labels = define_symbols([trace1, trace2])\n",
    "    weights1 = calc_weights(trace1, find_sub_conversations(trace1, labels, 0.3, 30)) #establish weights\n",
    "    weights2 = calc_weights(trace2, find_sub_conversations(trace2, labels, 0.3, 30))\n",
    "    \n",
    "    #fill table, horizontal -> vertical\n",
    "    for i in range(M):\n",
    "        for j in range(N):\n",
    "            \n",
    "            #original fill horizontal\n",
    "            if i == 0:\n",
    "                if j == 0: #first fill\n",
    "                    sim_table[i][j] = 1000\n",
    "                elif j == 1: #first insert\n",
    "                    sim_table[i][j] = weights2[j]\n",
    "                else: #rest fill, base insert scores\n",
    "                    sim_table[i][j] = weights2[j] + sim_table[i][j-1]\n",
    "            \n",
    "            #original fill vertical\n",
    "            elif j == 0:\n",
    "                if i == 0:#first fill\n",
    "                    sim_table[i][j] = 1000\n",
    "                elif i == 1:\n",
    "                    sim_table[i][j] = weights1[i]\n",
    "                else: #rest fill, base is the opposite of insert scores\n",
    "                    sim_table[i][j] = -weights1[i] + sim_table[i-1][j]\n",
    "            \n",
    "            elif trace1[i] == trace2[j]: #no changes\n",
    "                sim_table[i][j] = sim_table[i-1][j-1]\n",
    "            \n",
    "            else: #substitution, insertion or deletion\n",
    "                \n",
    "                #determine the max\n",
    "                op = np.argmax([sim_table[i-1][j], sim_table[i][j-1], sim_table[i-1][j-1]]) #in order, removal, insertion, substitution\n",
    "                if op == 0:\n",
    "                    sim_table[i][j] = -weights1[i] + sim_table[i-1][j] #removal\n",
    "                elif op == 1:\n",
    "                    sim_table[i][j] = weights2[j] + sim_table[i][j-1] #insertion\n",
    "                elif op == 2:\n",
    "                    sim_table[i][j] = -weights1[i]+weights2[j] + sim_table[i-1][j-1] #substitution\n",
    "                \n",
    "    return sim_table[i][j] #final score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#obtain freq for all labels in this trace\n",
    "def single_counts (trace, label_set):\n",
    "    \n",
    "    assert type(trace) == list\n",
    "    assert type(label_set) == list\n",
    "    \n",
    "    counts =  {}\n",
    "    \n",
    "    #initialize for consistency to label set\n",
    "    for label in label_set:\n",
    "        counts[\"{0}\".format(label)] = 0\n",
    "    \n",
    "    #iterate through trace for counts\n",
    "    for event in trace:\n",
    "        try:\n",
    "            counts[\"{0}\".format(event)] += 1\n",
    "        except:\n",
    "            raise ValueError('Trace contains a label not in the label_set given: {0}'.format(event))\n",
    "    \n",
    "    return counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat1 = pd.read_csv('./data/graham.norton.s22.e08_data.csv')\n",
    "dat2 = pd.read_csv('./data/graham.norton.s22.e12_data.csv')\n",
    "dat3 = pd.read_csv('./data/blackpink_data.csv')\n",
    "dat4 = pd.read_csv('./data/graham.norton.s22e01.csv')\n",
    "dat5 = pd.read_csv('./data/graham.norton.s22e02.csv')\n",
    "dat6 = pd.read_csv('./data/graham.norton.s22e07.csv')\n",
    "dat7 = pd.read_csv('./data/graham.norton.s22e15.csv')\n",
    "dat8 = pd.read_csv('./data/graham.norton.s22e19.csv')\n",
    "dat9 = pd.read_csv('./data/graham.norton.s24e10.csv')\n",
    "dat10 = pd.read_csv('./data/american_factory.csv')\n",
    "dat11 = pd.read_csv('./data/taylor_swift_miss_americana.csv')\n",
    "dat12 = pd.read_csv('./data/spider-man_into_the_spider-verse.csv')\n",
    "\n",
    "test1 = list(dat1.L) #graham norton\n",
    "test2 = list(dat2.L)\n",
    "test3 = list(dat3.L) #blackpink\n",
    "test4 = list(dat4.L) #graham norton\n",
    "test5 = list(dat5.L)\n",
    "test6 = list(dat6.L)\n",
    "test7 = list(dat7.L)\n",
    "test8 = list(dat8.L)\n",
    "test9 = list(dat9.L)\n",
    "test10 = list(dat10.L) #american factory\n",
    "test11 = list(dat11.L) #taylor swift\n",
    "test12 = list(dat12.L) #spider-verse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with PrefixSpan\n",
    "Have to convert the labeling to integer value and correct formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to desired format\n",
    "def create_convert_table (trace):\n",
    "    \n",
    "    assert type(trace) == list\n",
    "    \n",
    "    convert = {}\n",
    "    labels = set(trace)\n",
    "    x = 0\n",
    "    \n",
    "    for label in labels:\n",
    "        convert[label] = x\n",
    "        convert[x] = label\n",
    "        x += 1\n",
    "    \n",
    "    return convert\n",
    "\n",
    "def convert_trace_format (trace):\n",
    "    \n",
    "    assert type(trace) == list\n",
    "    \n",
    "    converted = []\n",
    "    table = create_convert_table(trace)\n",
    "    \n",
    "    for event in trace:\n",
    "        converted.append(table[event])\n",
    "    \n",
    "    return converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PrefixSpan variant\n",
    "def create_init_prefix(trace, min_supp):\n",
    "    \n",
    "    assert type(trace) == list\n",
    "    assert type(min_supp) == int\n",
    "    \n",
    "    labels = list(set(trace)) #create the list of symbols\n",
    "    \n",
    "    #create initial prefix\n",
    "    \n",
    "    #chunk trace for sequences\n",
    "    sequences = []\n",
    "    for i in range(0, len(trace), 30):\n",
    "        sequences.append((i,i+30)) #REFERENCE: sequences[i] = (start, end)\n",
    "    \n",
    "    #create bucket for symbols\n",
    "    bucket = {}\n",
    "    for label in labels:\n",
    "        bucket[\"{0}\".format(label)] = 0\n",
    "    \n",
    "    #check for support\n",
    "    for prefix in list(bucket.keys()):\n",
    "        \n",
    "        #check all sequences\n",
    "        for chunk in sequences:\n",
    "            if prefix in trace[chunk[0]:chunk[1]]: #in the sequence\n",
    "                bucket[\"{0}\".format(prefix)] += 1\n",
    "    \n",
    "    #drop lower than min_supp\n",
    "    for key in list(bucket.keys()):\n",
    "        if bucket[key] < min_supp:\n",
    "            bucket.pop(key)\n",
    "    \n",
    "    return bucket, sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'use.social.convention': 28,\n",
       "  'closed.question': 29,\n",
       "  'open.question': 24,\n",
       "  'recall': 19,\n",
       "  'misc': 8,\n",
       "  'respond.agree': 31,\n",
       "  'give.statement': 33,\n",
       "  'give.opinion': 31,\n",
       "  'deflection': 5,\n",
       "  'relax.atmosphere': 33,\n",
       "  'respond.deny': 8},\n",
       " [(0, 30),\n",
       "  (30, 60),\n",
       "  (60, 90),\n",
       "  (90, 120),\n",
       "  (120, 150),\n",
       "  (150, 180),\n",
       "  (180, 210),\n",
       "  (210, 240),\n",
       "  (240, 270),\n",
       "  (270, 300),\n",
       "  (300, 330),\n",
       "  (330, 360),\n",
       "  (360, 390),\n",
       "  (390, 420),\n",
       "  (420, 450),\n",
       "  (450, 480),\n",
       "  (480, 510),\n",
       "  (510, 540),\n",
       "  (540, 570),\n",
       "  (570, 600),\n",
       "  (600, 630),\n",
       "  (630, 660),\n",
       "  (660, 690),\n",
       "  (690, 720),\n",
       "  (720, 750),\n",
       "  (750, 780),\n",
       "  (780, 810),\n",
       "  (810, 840),\n",
       "  (840, 870),\n",
       "  (870, 900),\n",
       "  (900, 930),\n",
       "  (930, 960),\n",
       "  (960, 990),\n",
       "  (990, 1020),\n",
       "  (1020, 1050),\n",
       "  (1050, 1080)])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_init_prefix(test1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_projections(bucket, trace, sequences):\n",
    "    \n",
    "    #note: sequences are just the previous projections\n",
    "    \n",
    "    assert type(bucket) == dict #should be in the form {'use.social.convention': 23}\n",
    "    assert type(trace) == list #should be in the form ['misc', ..., 'use.social.convention']\n",
    "    assert type(sequences) == list #should be in the form [(start1, end1), (start2, end2), ... , (startN, endN)]\n",
    "    \n",
    "    projections = {}\n",
    "    \n",
    "    #generate a projection for each bucket item\n",
    "    \n",
    "    #initialize the list\n",
    "    for key in list(bucket.keys()):\n",
    "        projections[key] = []\n",
    "    \n",
    "    #populate by searching each sequence\n",
    "    for item in list(projections.keys()):\n",
    "        pref = item.split(\",\")\n",
    "        for seq_id in sequences: #should be in the form (start, end)\n",
    "            #look to replace the start index\n",
    "            sequence = trace[seq_id[0]:seq_id[1]]\n",
    "            for i in range(0, len(sequence), len(pref)):\n",
    "                if pref == sequence[i:i+len(pref)]: \n",
    "                    projections[item].append((seq_id[0]+i+len(pref)-1, seq_id[1]))\n",
    "                    break\n",
    "    \n",
    "    return projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'use.social.convention': [(0, 30),\n",
       "  (34, 60),\n",
       "  (60, 90),\n",
       "  (111, 120),\n",
       "  (121, 150),\n",
       "  (168, 180),\n",
       "  (222, 240),\n",
       "  (250, 270),\n",
       "  (364, 390),\n",
       "  (396, 420),\n",
       "  (475, 480),\n",
       "  (518, 540),\n",
       "  (540, 570),\n",
       "  (595, 600),\n",
       "  (623, 630),\n",
       "  (660, 690),\n",
       "  (690, 720),\n",
       "  (727, 750),\n",
       "  (769, 780),\n",
       "  (817, 840),\n",
       "  (845, 870),\n",
       "  (894, 900),\n",
       "  (900, 930),\n",
       "  (931, 960),\n",
       "  (960, 990),\n",
       "  (999, 1020),\n",
       "  (1032, 1050),\n",
       "  (1060, 1080)],\n",
       " 'closed.question': [(68, 90),\n",
       "  (95, 120),\n",
       "  (123, 150),\n",
       "  (157, 180),\n",
       "  (189, 210),\n",
       "  (211, 240),\n",
       "  (277, 300),\n",
       "  (309, 330),\n",
       "  (330, 360),\n",
       "  (365, 390),\n",
       "  (390, 420),\n",
       "  (420, 450),\n",
       "  (456, 480),\n",
       "  (482, 510),\n",
       "  (546, 570),\n",
       "  (574, 600),\n",
       "  (606, 630),\n",
       "  (644, 660),\n",
       "  (666, 690),\n",
       "  (700, 720),\n",
       "  (730, 750),\n",
       "  (772, 780),\n",
       "  (785, 810),\n",
       "  (810, 840),\n",
       "  (904, 930),\n",
       "  (939, 960),\n",
       "  (969, 990),\n",
       "  (991, 1020),\n",
       "  (1023, 1050)],\n",
       " 'open.question': [(78, 90),\n",
       "  (100, 120),\n",
       "  (125, 150),\n",
       "  (151, 180),\n",
       "  (180, 210),\n",
       "  (239, 240),\n",
       "  (293, 300),\n",
       "  (308, 330),\n",
       "  (338, 360),\n",
       "  (410, 420),\n",
       "  (421, 450),\n",
       "  (476, 480),\n",
       "  (491, 510),\n",
       "  (567, 570),\n",
       "  (573, 600),\n",
       "  (653, 660),\n",
       "  (681, 690),\n",
       "  (722, 750),\n",
       "  (787, 810),\n",
       "  (824, 840),\n",
       "  (918, 930),\n",
       "  (966, 990),\n",
       "  (1000, 1020),\n",
       "  (1029, 1050)],\n",
       " 'recall': [(143, 150),\n",
       "  (160, 180),\n",
       "  (188, 210),\n",
       "  (210, 240),\n",
       "  (286, 300),\n",
       "  (307, 330),\n",
       "  (383, 390),\n",
       "  (393, 420),\n",
       "  (433, 450),\n",
       "  (479, 480),\n",
       "  (480, 510),\n",
       "  (510, 540),\n",
       "  (702, 720),\n",
       "  (744, 750),\n",
       "  (750, 780),\n",
       "  (916, 930),\n",
       "  (1006, 1020),\n",
       "  (1020, 1050),\n",
       "  (1050, 1080)],\n",
       " 'misc': [(165, 180),\n",
       "  (198, 210),\n",
       "  (214, 240),\n",
       "  (241, 270),\n",
       "  (553, 570),\n",
       "  (813, 840),\n",
       "  (847, 870),\n",
       "  (870, 900)],\n",
       " 'respond.agree': [(82, 90),\n",
       "  (97, 120),\n",
       "  (120, 150),\n",
       "  (150, 180),\n",
       "  (182, 210),\n",
       "  (226, 240),\n",
       "  (273, 300),\n",
       "  (304, 330),\n",
       "  (333, 360),\n",
       "  (367, 390),\n",
       "  (391, 420),\n",
       "  (423, 450),\n",
       "  (477, 480),\n",
       "  (483, 510),\n",
       "  (550, 570),\n",
       "  (584, 600),\n",
       "  (607, 630),\n",
       "  (632, 660),\n",
       "  (668, 690),\n",
       "  (701, 720),\n",
       "  (729, 750),\n",
       "  (764, 780),\n",
       "  (786, 810),\n",
       "  (822, 840),\n",
       "  (843, 870),\n",
       "  (906, 930),\n",
       "  (941, 960),\n",
       "  (970, 990),\n",
       "  (990, 1020),\n",
       "  (1024, 1050),\n",
       "  (1055, 1080)],\n",
       " 'give.statement': [(22, 30),\n",
       "  (50, 60),\n",
       "  (116, 120),\n",
       "  (122, 150),\n",
       "  (161, 180),\n",
       "  (203, 210),\n",
       "  (240, 270),\n",
       "  (288, 300),\n",
       "  (321, 330),\n",
       "  (350, 360),\n",
       "  (362, 390),\n",
       "  (427, 450),\n",
       "  (460, 480),\n",
       "  (481, 510),\n",
       "  (522, 540),\n",
       "  (543, 570),\n",
       "  (571, 600),\n",
       "  (608, 630),\n",
       "  (630, 660),\n",
       "  (661, 690),\n",
       "  (697, 720),\n",
       "  (724, 750),\n",
       "  (762, 780),\n",
       "  (792, 810),\n",
       "  (812, 840),\n",
       "  (844, 870),\n",
       "  (895, 900),\n",
       "  (901, 930),\n",
       "  (932, 960),\n",
       "  (965, 990),\n",
       "  (1004, 1020),\n",
       "  (1025, 1050),\n",
       "  (1056, 1080)],\n",
       " 'give.opinion': [(24, 30),\n",
       "  (30, 60),\n",
       "  (66, 90),\n",
       "  (90, 120),\n",
       "  (139, 150),\n",
       "  (155, 180),\n",
       "  (183, 210),\n",
       "  (223, 240),\n",
       "  (243, 270),\n",
       "  (271, 300),\n",
       "  (303, 330),\n",
       "  (344, 360),\n",
       "  (361, 390),\n",
       "  (394, 420),\n",
       "  (424, 450),\n",
       "  (455, 480),\n",
       "  (489, 510),\n",
       "  (544, 570),\n",
       "  (570, 600),\n",
       "  (600, 630),\n",
       "  (633, 660),\n",
       "  (665, 690),\n",
       "  (691, 720),\n",
       "  (720, 750),\n",
       "  (763, 780),\n",
       "  (794, 810),\n",
       "  (833, 840),\n",
       "  (914, 930),\n",
       "  (936, 960),\n",
       "  (993, 1020),\n",
       "  (1022, 1050)],\n",
       " 'deflection': [(103, 120), (158, 180), (345, 360), (430, 450), (463, 480)],\n",
       " 'relax.atmosphere': [(25, 30),\n",
       "  (32, 60),\n",
       "  (62, 90),\n",
       "  (96, 120),\n",
       "  (130, 150),\n",
       "  (172, 180),\n",
       "  (234, 240),\n",
       "  (245, 270),\n",
       "  (270, 300),\n",
       "  (300, 330),\n",
       "  (334, 360),\n",
       "  (376, 390),\n",
       "  (395, 420),\n",
       "  (431, 450),\n",
       "  (450, 480),\n",
       "  (521, 540),\n",
       "  (545, 570),\n",
       "  (582, 600),\n",
       "  (601, 630),\n",
       "  (636, 660),\n",
       "  (677, 690),\n",
       "  (695, 720),\n",
       "  (736, 750),\n",
       "  (761, 780),\n",
       "  (780, 810),\n",
       "  (816, 840),\n",
       "  (840, 870),\n",
       "  (907, 930),\n",
       "  (930, 960),\n",
       "  (979, 990),\n",
       "  (995, 1020),\n",
       "  (1031, 1050),\n",
       "  (1057, 1080)],\n",
       " 'respond.deny': [(70, 90),\n",
       "  (331, 360),\n",
       "  (360, 390),\n",
       "  (575, 600),\n",
       "  (670, 690),\n",
       "  (773, 780),\n",
       "  (811, 840),\n",
       "  (1001, 1020)]}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a,b = create_init_prefix(test1, 2)\n",
    "c = generate_projections(a, test1, b)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_and_drop(projections, trace, min_supp):\n",
    "\n",
    "    assert type(projections) == dict #should be in the form (\"alpha\": [(start, end), ... (startN, endN)])\n",
    "    assert type(trace) == list\n",
    "    \n",
    "    labels = list(set(trace))\n",
    "    proj_list = []\n",
    "    \n",
    "    #for every projection, count the i+1 patterns\n",
    "    for proj in list(projections.keys()):\n",
    "        #append from the labels to initialize\n",
    "        iplus1_count = {}\n",
    "        for L in labels:\n",
    "            prefix = proj.split(\",\") + [L]\n",
    "            iplus1_count[\"{0}\".format((\", \").join(prefix))] = 0\n",
    "        \n",
    "            #count the labels\n",
    "            sequences = projections[proj]\n",
    "            for seq_id in sequences: #should be in the form (start, end)\n",
    "                sequence = trace[seq_id[0]:seq_id[1]]\n",
    "                for i in range(0, len(sequence), len(prefix)):\n",
    "                    if prefix == sequence[i:i+len(prefix)]:\n",
    "                        iplus1_count[\"{0}\".format((\", \").join(prefix))] += 1\n",
    "                        break\n",
    "\n",
    "            #drop\n",
    "            for k in list(iplus1_count.keys()):\n",
    "                if iplus1_count[k] <= min_supp:\n",
    "                    iplus1_count.pop(k)\n",
    "\n",
    "        #stop condition\n",
    "        if len(iplus1_count) <= 1:\n",
    "            continue           \n",
    "                    \n",
    "        #output to proj_list\n",
    "        proj_list.append(iplus1_count)\n",
    "    \n",
    "    return proj_list       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'use.social.convention, use.social.convention': 10,\n",
       "  'use.social.convention, closed.question': 3,\n",
       "  'use.social.convention, open.question': 4,\n",
       "  'use.social.convention, give.statement': 12,\n",
       "  'use.social.convention, give.opinion': 5,\n",
       "  'use.social.convention, relax.atmosphere': 3},\n",
       " {'closed.question, closed.question': 8,\n",
       "  'closed.question, respond.agree': 20,\n",
       "  'closed.question, relax.atmosphere': 3,\n",
       "  'closed.question, respond.deny': 4},\n",
       " {'open.question, closed.question': 4,\n",
       "  'open.question, open.question': 7,\n",
       "  'open.question, respond.agree': 11,\n",
       "  'open.question, give.statement': 3,\n",
       "  'open.question, relax.atmosphere': 4},\n",
       " {'recall, closed.question': 3,\n",
       "  'recall, recall': 14,\n",
       "  'recall, give.statement': 3,\n",
       "  'recall, give.opinion': 3},\n",
       " {'respond.agree, use.social.convention': 3,\n",
       "  'respond.agree, closed.question': 7,\n",
       "  'respond.agree, open.question': 6,\n",
       "  'respond.agree, recall': 4,\n",
       "  'respond.agree, respond.agree': 5,\n",
       "  'respond.agree, give.statement': 15,\n",
       "  'respond.agree, give.opinion': 15,\n",
       "  'respond.agree, relax.atmosphere': 7},\n",
       " {'give.statement, use.social.convention': 8,\n",
       "  'give.statement, closed.question': 11,\n",
       "  'give.statement, open.question': 3,\n",
       "  'give.statement, respond.agree': 5,\n",
       "  'give.statement, give.statement': 23,\n",
       "  'give.statement, give.opinion': 10,\n",
       "  'give.statement, relax.atmosphere': 9},\n",
       " {'give.opinion, use.social.convention': 3,\n",
       "  'give.opinion, closed.question': 6,\n",
       "  'give.opinion, open.question': 4,\n",
       "  'give.opinion, recall': 4,\n",
       "  'give.opinion, respond.agree': 8,\n",
       "  'give.opinion, give.statement': 13,\n",
       "  'give.opinion, give.opinion': 20,\n",
       "  'give.opinion, relax.atmosphere': 9},\n",
       " {'relax.atmosphere, use.social.convention': 7,\n",
       "  'relax.atmosphere, closed.question': 12,\n",
       "  'relax.atmosphere, respond.agree': 7,\n",
       "  'relax.atmosphere, give.statement': 6,\n",
       "  'relax.atmosphere, give.opinion': 9,\n",
       "  'relax.atmosphere, relax.atmosphere': 19}]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = compute_and_drop(c, test1, 2)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
