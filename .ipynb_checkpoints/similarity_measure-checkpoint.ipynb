{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Edit-distance operations are defined as \n",
    "* (a,a) denotes a match of symbols at the given position\n",
    "* (a,-) denotes deletion of symbol 'a' at some position\n",
    "* (-,b) denotes insertion of symbol 'b' at some position\n",
    "* (a,b) denotes replacement of 'a' with 'b' at some position, and a != b\n",
    "We assign a separate cost for each of these operations according to our needs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for simplicity and completeness sake, we define a simple levenshtein distance function first\n",
    "\n",
    "def basic_distance (trace1, trace2):\n",
    "\n",
    "    M = len(trace1)\n",
    "    N = len(trace2)\n",
    "    edit_table = np.zeros((M,N)) #establish table\n",
    "\n",
    "    #fill table\n",
    "    for i in range(M):\n",
    "        for j in range(N):\n",
    "\n",
    "            if i == 0:\n",
    "                edit_table[i][j] = j\n",
    "\n",
    "            elif j ==0:\n",
    "                edit_table[i][j] = i\n",
    "\n",
    "            elif trace1[i-1] == trace2[j-1]:\n",
    "                edit_table[i][j] = edit_table[i-1][j-1]\n",
    "\n",
    "            else:\n",
    "                edit_table[i][j] = 1 + min(edit_table[i-1][j], edit_table[i][j-1], edit_table[i-1][j-1]) #scoring done here\n",
    "\n",
    "    return edit_table[i][j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample test\n",
    "dat1 = pd.read_csv('./graham.norton.s22.e08_data.csv')\n",
    "dat2 = pd.read_csv('./graham.norton.s22.e12_data.csv')\n",
    "test1 = list(dat1.L)\n",
    "test2 = list(dat2.L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "517.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_distance(test1,test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "517"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#baseline\n",
    "import nltk\n",
    "nltk.edit_distance(test1,test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we have to alter the function to accomodate for different scoring metrics according to the paper\n",
    "* substitution of uncorrelated activities should be discouraged\n",
    "* substitution of contrasting activities should be penalized\n",
    "* insertion of activities out of context should be discouraged\n",
    "* substitution of correlated activities should be encouraged in proportion to the degree of similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#similarity is calculated to address substitution costs\n",
    "def sub_cost (eventlog):\n",
    "    \n",
    "    g3_freq = {}\n",
    "    conteX = {}\n",
    "    \n",
    "    '''\n",
    "    g3_freq is a dictionary in the form:\n",
    "    key: triple of labels, i.e: \"respond.agree, open.question, give.opinion\"\n",
    "    value: int of frequency value, i.e: 20\n",
    "    \n",
    "    conteX is a dictionary in the form:\n",
    "    key: single or pair label, i.e: \"respond.agree\", \"respond.agree, open.question\"\n",
    "    value: list of label pairs\n",
    "    value: set of label pairs, i.e: [\"respond.agree, give.opinion\", \"closed.question, relax.atmosphere\"]\n",
    "    **value depends on whether it is a singular or pair label used as a key\n",
    "    \n",
    "    co_occur is a dictionary in the form:\n",
    "    key: a context and label pair, i.e: \"open.question, give.opinion\"(\"relax.atmosphere\", \"use.social.convention\")\n",
    "    value: int of the co-occurence value i.e: 20\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    #set all of our traces\n",
    "    log = \"\"\n",
    "    for item in eventlog:\n",
    "        log = log + item\n",
    "    \n",
    "    #STEP 1: let A be the alphabet\n",
    "    symbols = set(log)\n",
    "    \n",
    "    #set conteX\n",
    "    for item in symbols:\n",
    "        conteX[item] = []\n",
    "        \n",
    "    #STEP 2: find the 3 grams and their freq \n",
    "    for i in range(len(item)-3):\n",
    "        try:\n",
    "            g3_freq[\", \".join(list(log[i:i+3]))] += 1\n",
    "        except:\n",
    "            g3_freq[\", \".join(list(log[i:i+3]))] = 0\n",
    "\n",
    "    #STEP 3: determine the set of contexts for each symbols from the 3-grams\n",
    "    for threegram in list(g3_freq.keys()):\n",
    "        con_a, sym, con_b = threegram.split(\", \")\n",
    "        conteX[sym].append(con_a + \", \" + con_b)\n",
    "\n",
    "    #STEP 4: determine context for each pair\n",
    "    for p1 in symbols:\n",
    "        for p2 in symbols:\n",
    "            if p1 != p2:\n",
    "                conteX[\"{0}, {1}\".format(p1, p2)] = set(conteX[p1] + conteX[p2])\n",
    "\n",
    "    #STEP 5: determine co-occurrence\n",
    "    co_occur = {}\n",
    "    for p1 in symbols:\n",
    "        for p2 in symbols:\n",
    "            if p1 != p2:\n",
    "                for con in conteX[\"{0}, {1}\".format(p1,p2)]:\n",
    "                    #consider the 3-grams for each of the context in this pair\n",
    "                    co_occur[\"{0}({1}, {2})\".format(con,p1,p2)] = g3_freq[\"{0}, {1}, {2}\".format(con.split(\", \")[0], p1, con.split(\", \")[1])] * g3_freq[\"{0}, {1}, {2}\".format(con.split(\", \")[0], p2, con.split(\", \")[1])]\n",
    "            elif p1 == p2:\n",
    "                for con in conteX[\"{0}, {1}\".format(p1,p2)]:\n",
    "                    co_occur[\"{0}({1}, {2})\".format(con,p1,p2)] = (g3_freq[\"{0}, {1}, {2}\".format(con.split(\", \")[0], p1, con.split(\", \")[1])]*(g3_freq[\"{0}, {1}, {2}\".format(con.split(\", \")[0], p1, con.split(\", \")[1])]-1))//2\n",
    "    \n",
    "    #STEP 6: calculate co-occurrence combinations\n",
    "    co_occur_combo = {}\n",
    "    for p1 in symbols:\n",
    "        for p2 in symbols:\n",
    "            for con in conteX[\"{0}, {1}\".format(p1,p2)]:\n",
    "                try:\n",
    "                    co_occur_combo[\"{0}, {1}\".format(p1, p2)] += co_occur[\"{0}({1}, {2})\".format(con, p1, p2)]\n",
    "                except:\n",
    "                    co_occur_combo[\"{0}, {1}\".format(p1, p2)] = 0\n",
    "        \n",
    "    #STEP 7: define the norm of all the count of co-occurence combinations\n",
    "    norm = 0\n",
    "    for k in co_occur_combo.keys():\n",
    "        norm += co_occur_combo[k]\n",
    "    \n",
    "    #STEP 8: define the matrix\n",
    "    mat = {}\n",
    "    for p1 in symbols:\n",
    "        for p2 in symbols:\n",
    "            mat[\"{0}, {1}\".format(p1,p2)] = co_occur_combo[\"{0}, {1}\".format(p1, p2)]/norm\n",
    "    \n",
    "    #STEP 9: define probability of occurrence\n",
    "    p_occur = {}\n",
    "    for s in symbols:\n",
    "        par = 1\n",
    "        for b in symbols:\n",
    "            if s != b:\n",
    "                try:\n",
    "                    p[s] += mat[\"{0}, {1}\".format(s,b)]\n",
    "                    par += 1\n",
    "                except:\n",
    "                    p[s] = 0\n",
    "        p[s] += mat[\"{0}, {1}\".format(s,s)]\n",
    "        p[s] = p[s]/par\n",
    "    \n",
    "    #STEP 10: define expected values matrix\n",
    "    E_mat = {}\n",
    "    for a in symbols:\n",
    "        for b in symbols:\n",
    "            if a == b:\n",
    "                E_mat[\"{0}, {1}\".format(a,b)] = p_occur[a]**2\n",
    "            else:\n",
    "                E_mat[\"{0}, {1}\".format(a,b)] = 2*p_occur[a]*p_occur[b]\n",
    "    \n",
    "    #STEP 11: define matrix of scores\n",
    "    scores = {}\n",
    "    for a in symbols:\n",
    "        for b in symbols:\n",
    "            if a != b:\n",
    "                scores[\"{0}, {1}\".format(a,b)] = np.log2(mat[\"{0}, {1}\".format(a,b)]/E_mat[\"{0}, {1}\".format(a,b)])\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'symbols' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-bb405e117d57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msmalltest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_cost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmalltest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-14-4b97e260e090>\u001b[0m in \u001b[0;36msub_cost\u001b[0;34m(eventlog)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m#set conteX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msymbols\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mconteX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'symbols' referenced before assignment"
     ]
    }
   ],
   "source": [
    "smalltest = test1[10:50]\n",
    "print(sub_cost(smalltest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
